{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "unavailable-public",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import csv\n",
    "import tqdm\n",
    "import copy\n",
    "import click\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from string import digits\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "seed = 42\n",
    "epochs = 200\n",
    "batch_size = 32\n",
    "learning_rate = 1e-3\n",
    "context_frames = 10\n",
    "sequence_length = 16\n",
    "lookback = sequence_length\n",
    "\n",
    "context_epochs = 20\n",
    "context_batch_size = 1\n",
    "context_learning_rate = 1e-3\n",
    "context_data_length = 20\n",
    "\n",
    "valid_train_split = 0.8  # precentage of train data from total\n",
    "test_train_split = 0.9  # precentage of train data from total\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")#  use gpu if available\n",
    "################################# CHANGE THIS!!!!  #################################\n",
    "model_path = \"/home/user/Robotics/slip_detection_model/slip_detection_model/manual_data_models/models/simple_model_002/\"\n",
    "################################# CHANGE THIS!!!!  #################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "demonstrated-hundred",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator:\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "        data_map = []\n",
    "        with open(data_dir + 'map.csv', 'r') as f:  # rb\n",
    "            reader = csv.reader(f)\n",
    "            for row in reader:\n",
    "                data_map.append(row)\n",
    "\n",
    "        if len(data_map) <= 1: # empty or only header\n",
    "            print(\"No file map found\")\n",
    "            exit()\n",
    "\n",
    "        self.data_map = data_map\n",
    "\n",
    "    def load_full_data(self):\n",
    "        dataset_train = FullDataSet(self.data_dir, self.data_map, type_=\"train\")\n",
    "        dataset_valid = FullDataSet(self.data_dir, self.data_map, type_=\"valid\")\n",
    "        dataset_test = FullDataSet(self.data_dir, self.data_map, type_=\"test\")\n",
    "        transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "        train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "        valid_loader = torch.utils.data.DataLoader(dataset_valid, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=False)\n",
    "        return train_loader, valid_loader, test_loader\n",
    "\n",
    "\n",
    "class FullDataSet():\n",
    "    def __init__(self, data_dir, data_map, type_=\"train\"):\n",
    "        dataset_full = []\n",
    "        for index, value in enumerate(data_map[1:]):  # ignore header\n",
    "            robot = np.load(data_dir + value[0])\n",
    "            xela1 = np.load(data_dir + value[1])\n",
    "            xela2 = np.load(data_dir + value[2])\n",
    "            experiment = np.load(data_dir + value[-2])\n",
    "            time_step  = np.load(data_dir + value[-1])\n",
    "            for i in range(len(robot)):\n",
    "                dataset_full.append([robot[i].astype(np.float32),\n",
    "                                     xela1[i].astype(np.float32),\n",
    "                                     xela2[i].astype(np.float32),\n",
    "                                     experiment[i],\n",
    "                                     time_step[i]])\n",
    "        if type_ == \"train\":\n",
    "            self.samples = dataset_full[0:int(len(dataset_full)*test_train_split)]\n",
    "        elif type_ == \"valid\":\n",
    "            self.samples = dataset_full[int(len(dataset_full)*(valid_train_split)):int(len(dataset_full)*test_train_split)]\n",
    "        elif type_ == \"test\":\n",
    "            self.samples = dataset_full[int(len(dataset_full)*test_train_split):-1]\n",
    "\n",
    "        data_map = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return(self.samples[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "handmade-valuation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FullModel, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(96, 96).to(device)  # tactile\n",
    "        self.lstm2 = nn.LSTM(6, 6).to(device)  # pos_vel\n",
    "        self.fc1 = nn.Linear(96+6, 96)  # tactile + pos_vel\n",
    "        self.lstm3 = nn.LSTM(96, 96).to(device)  # pos_vel\n",
    "\n",
    "    def forward(self, tactiles, actions):\n",
    "        state = actions[0]\n",
    "        state.to(device)\n",
    "        batch_size__ = tactiles.shape[1]\n",
    "        outputs = []\n",
    "        hidden1 = (torch.rand(1,batch_size__,96).to(device), torch.rand(1,batch_size__,96).to(device))\n",
    "        hidden2 = (torch.rand(1,batch_size__,6).to(device), torch.rand(1,batch_size__,6).to(device))\n",
    "        hidden3 = (torch.rand(1,batch_size__,96).to(device), torch.rand(1,batch_size__,96).to(device))\n",
    "        for index, (sample_tactile, sample_action) in enumerate(zip(tactiles.squeeze(), actions.squeeze())):\n",
    "            sample_tactile.to(device)\n",
    "            sample_action.to(device)\n",
    "            # 2. Run through lstm:\n",
    "            if index > context_frames-1:\n",
    "                out1, hidden1 = self.lstm1(out4, hidden1)\n",
    "                out2, hidden2 = self.lstm2(sample_action.unsqueeze(0), hidden2)\n",
    "                robot_and_tactile = torch.cat((out2.squeeze(), out1.squeeze()), 1)\n",
    "                out3 = self.fc1(robot_and_tactile.unsqueeze(0).cpu().detach())\n",
    "                out4, hidden3 = self.lstm3(out3.to(device), hidden3)\n",
    "                outputs.append(out4.squeeze())\n",
    "            else:\n",
    "                out1, hidden1 = self.lstm1(sample_tactile.unsqueeze(0), hidden1)\n",
    "                out2, hidden2 = self.lstm2(sample_action.unsqueeze(0), hidden2)\n",
    "                robot_and_tactile = torch.cat((out2.squeeze(), out1.squeeze()), 1)\n",
    "                out3 = self.fc1(robot_and_tactile.unsqueeze(0).cpu().detach())\n",
    "                out4, hidden3 = self.lstm3(out3.to(device), hidden3)\n",
    "\n",
    "        return torch.stack(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "unique-platinum",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "        self.train_full_loader, self.valid_full_loader, self.test_full_loader = BG.load_full_data()\n",
    "        self.full_model = FullModel()\n",
    "        self.criterion = nn.L1Loss()\n",
    "        self.optimizer = optim.Adam(self.full_model.parameters(), lr=learning_rate)\n",
    "\n",
    "    def train_full_model(self):\n",
    "        best_model_loss_score = 10.0 \n",
    "        self.plot_training_loss = []\n",
    "        self.plot_validation_loss = []\n",
    "        previous_val_mean_loss = 1.0\n",
    "        early_stop_clock = 0\n",
    "        progress_bar = tqdm.tqdm(range(0, epochs), total=(epochs*len(self.train_full_loader)))\n",
    "        mean_test = 0\n",
    "        for epoch in progress_bar:\n",
    "            loss = 0\n",
    "            losses = 0.0\n",
    "            for index, batch_features in enumerate(self.train_full_loader):\n",
    "                action   = batch_features[0].permute(1,0,2).to(device)\n",
    "                tactile1 = batch_features[1].permute(1,0,2).to(device)\n",
    "                tactile2 = batch_features[1].permute(1,0,2).to(device)\n",
    "                tactile  = torch.dstack((tactile1,tactile2))\n",
    "                tactile_predictions = self.full_model.forward(tactiles=tactile, actions=action) # Step 3. Run our forward pass.\n",
    "                self.optimizer.zero_grad()\n",
    "                loss = self.criterion(tactile_predictions.to(device), tactile[context_frames:])\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                losses += loss.item()\n",
    "                if index:\n",
    "                    mean = losses / index\n",
    "                else:\n",
    "                    mean = 0\n",
    "                progress_bar.set_description(\"epoch: {}, \".format(epoch) + \"loss: {:.4f}, \".format(float(loss.item())) + \"mean loss: {:.4f}, \".format(mean))\n",
    "                progress_bar.update()\n",
    "            self.plot_training_loss.append(mean)\n",
    "\n",
    "            val_losses = 0.0\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for index__, batch_features in enumerate(self.valid_full_loader):\n",
    "                    action = batch_features[0].permute(1,0,2).to(device)\n",
    "                    tactile1 = batch_features[1].permute(1,0,2).to(device)\n",
    "                    tactile2 = batch_features[1].permute(1,0,2).to(device)\n",
    "                    tactile  = torch.dstack((tactile1,tactile2))\n",
    "                    tactile_predictions = self.full_model.forward(tactiles=tactile, actions=action)  # Step 3. Run our forward pass.\n",
    "                    self.optimizer.zero_grad()\n",
    "                    val_loss = self.criterion(tactile_predictions.to(device), tactile[context_frames:])\n",
    "                    val_losses += val_loss.item()\n",
    "\n",
    "            print(\"Validation mean loss: {:.4f}, \".format(val_losses / index__))\n",
    "            self.plot_validation_loss.append(val_losses / index__)\n",
    "            if previous_val_mean_loss < val_losses / index__:\n",
    "                early_stop_clock +=1\n",
    "                previous_val_mean_loss = val_losses / index__ \n",
    "                if early_stop_clock == 3:\n",
    "                    print(\"Early stopping\")\n",
    "                    break\n",
    "            else:\n",
    "                if (val_losses / index__) < best_model_loss_score:\n",
    "                    self.strongest_model = copy.deepcopy(self.full_model)\n",
    "                early_stop_clock = 0\n",
    "                previous_val_mean_loss = val_losses / index__\n",
    "        plt.plot(self.plot_training_loss, c=\"r\", label=\"train loss MAE\")\n",
    "        plt.plot(self.plot_validation_loss, c='b', label=\"val loss MAE\")\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        plt.show()\n",
    "        plt.savefig(model_path + '/model_training_plot.png', dpi=300)\n",
    "        np.save(model_path + 'training_loss', np.asarray(self.plot_training_loss))\n",
    "        np.save(model_path + 'validation_loss', np.asarray(self.plot_validation_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "temporal-aging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/home/user/Robotics/Data_sets/slip_detection/manual_slip_detection/'\n",
    "BG = BatchGenerator(data_dir)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-guide",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 0.0353, mean loss: 0.0426, :   2%|▏         | 2849/142100 [01:15<9:18:09,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0380, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 2, loss: 0.0358, mean loss: 0.0378, :   4%|▍         | 5691/142100 [02:23<6:43:43,  5.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0301, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 3, loss: 0.0236, mean loss: 0.0334, :   6%|▌         | 8535/142100 [03:37<9:55:05,  3.74it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0254, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 3, loss: 0.0272, mean loss: 0.0295, :   6%|▌         | 8737/142100 [03:43<1:07:47, 32.78it/s]"
     ]
    }
   ],
   "source": [
    "MT = ModelTrainer(data_dir)\n",
    "MT.train_full_model()\n",
    "print(\"finished training\")\n",
    "torch.save(MT.strongest_model, model_path + \"full_model\")\n",
    "model = torch.load(model_path + \"full_model\")\n",
    "model.eval()\n",
    "print(\"saved the model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "killing-anniversary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test loss MAE(L1): ', 0.0]\n",
      "['test loss MSE: ', 0.0]\n",
      "['test loss MAE(L1) timestep 1: ', 0.02047521910437989]\n",
      "['test loss MSE timestep 1: ', 0.0015837723040252939]\n",
      "['test loss MAE(L1) timestep 5: ', 0.02229656567501407]\n",
      "['test loss MSE timestep 5: ', 0.0018254274090900757]\n",
      "['test loss MAE(L1) timestep 10: ', 0.018959840466194446]\n",
      "['test loss MSE timestep 10: ', 0.0017116586486187611]\n",
      "['sheer x test loss MAE(L1): ', 0.02047521910437989]\n",
      "['sheer x test loss MSE: ', 0.0015837723040252939]\n",
      "['sheer y test loss MAE(L1): ', 0.02229656567501407]\n",
      "['sheer y test loss MSE: ', 0.0018254274090900757]\n",
      "['z test loss MAE(L1): ', 0.018959840466194446]\n",
      "['z test loss MSE: ', 0.0017116586486187611]\n",
      "['sheer x test loss MAE(L1) timestep 1: ', 0.014294787641200754]\n",
      "['sheer x test loss MSE timestep 1: ', 0.000647175583077432]\n",
      "['sheer y test loss MAE(L1) timestep 1: ', 0.014787987584898632]\n",
      "['sheer y test loss MSE timestep 1: ', 0.0006762196027488071]\n",
      "['z test loss MAE(L1) timestep 1: ', 0.013990507787832665]\n",
      "['z test loss MSE timestep 1: ', 0.0007711782640225941]\n",
      "['sheer x test loss MAE(L1) timestep 5: ', 0.019872972713635556]\n",
      "['sheer x test loss MSE timestep 5: ', 0.0014381832697951708]\n",
      "['sheer y test loss MAE(L1) timestep 5: ', 0.021591425784641786]\n",
      "['sheer y test loss MSE timestep 5: ', 0.0016393769907327147]\n",
      "['z test loss MAE(L1) timestep 5: ', 0.018257952212459513]\n",
      "['z test loss MSE timestep 5: ', 0.0015518331919526054]\n",
      "['sheer x test loss MAE(L1) timestep 10: ', 0.026521067222255088]\n",
      "['sheer x test loss MSE timestep 10: ', 0.002570015263913702]\n",
      "['sheer y test loss MAE(L1) timestep 10: ', 0.029528492462215207]\n",
      "['sheer y test loss MSE timestep 10: ', 0.003064573665404977]\n",
      "['z test loss MAE(L1) timestep 10: ', 0.024147349196146167]\n",
      "['z test loss MSE timestep 10: ', 0.002742692956633705]\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(model_path + \"full_model\")\n",
    "model.eval()\n",
    "# test model on the full test sample:\n",
    "# model = MT.strongest_model\n",
    "data_dir = MT.data_dir\n",
    "\n",
    "criterion1 = nn.L1Loss()\n",
    "criterion2 = nn.MSELoss()\n",
    "\n",
    "test_lossesMAE_x = 0.0\n",
    "test_lossesMSE_x = 0.0\n",
    "test_lossesMAE_y = 0.0\n",
    "test_lossesMSE_y = 0.0\n",
    "test_lossesMAE_z = 0.0\n",
    "test_lossesMSE_z = 0.0\n",
    "\n",
    "test_lossesMAE_t1 = 0.0\n",
    "test_lossesMSE_t1 = 0.0\n",
    "test_lossesMAE_t5 = 0.0\n",
    "test_lossesMSE_t5 = 0.0\n",
    "test_lossesMAE_t10 = 0.0\n",
    "test_lossesMSE_t10 = 0.0\n",
    "\n",
    "test_lossesMAE_x_ts1 = 0.0\n",
    "test_lossesMSE_x_ts1 = 0.0\n",
    "test_lossesMAE_y_ts1 = 0.0\n",
    "test_lossesMSE_y_ts1 = 0.0\n",
    "test_lossesMAE_z_ts1 = 0.0\n",
    "test_lossesMSE_z_ts1 = 0.0\n",
    "\n",
    "test_lossesMAE_x_ts5 = 0.0\n",
    "test_lossesMSE_x_ts5 = 0.0\n",
    "test_lossesMAE_y_ts5 = 0.0\n",
    "test_lossesMSE_y_ts5 = 0.0\n",
    "test_lossesMAE_z_ts5 = 0.0\n",
    "test_lossesMSE_z_ts5 = 0.0\n",
    "\n",
    "test_lossesMAE_x_ts10 = 0.0\n",
    "test_lossesMSE_x_ts10 = 0.0\n",
    "test_lossesMAE_y_ts10 = 0.0\n",
    "test_lossesMSE_y_ts10 = 0.0\n",
    "test_lossesMAE_z_ts10 = 0.0\n",
    "test_lossesMSE_z_ts10 = 0.0\n",
    "\n",
    "tactile_predictions = []\n",
    "tactile_groundtruth = []\n",
    "experiment_time_steps = []\n",
    "test_lossesMAE = 0.0\n",
    "test_lossesMSE = 0.0\n",
    "with torch.no_grad():\n",
    "    for index__, batch_features in enumerate(MT.test_full_loader):\n",
    "        # 2. Reshape data and send to device:\n",
    "        action = batch_features[0].permute(1,0,2).to(device)\n",
    "        tactile1 = batch_features[1].permute(1,0,2).to(device)\n",
    "        tactile2 = batch_features[1].permute(1,0,2).to(device)\n",
    "        tactile  = torch.dstack((tactile1,tactile2))\n",
    "        tp = model.forward(tactiles=tactile, actions=action)\n",
    "        experiment_time_steps.append([batch_features[3], batch_features[4]])\n",
    "        tactile_predictions.append(tp)  # Step 3. Run our forward pass.\n",
    "        tactile_groundtruth.append(tactile[context_frames:])\n",
    "        # calculate losses for specific timesteps\n",
    "        test_lossMAE_t1 = criterion1(tp[0,:,:].to(device), tactile[context_frames:][0,:,:])\n",
    "        test_lossesMAE_t1 += test_lossMAE_t1.item() \n",
    "        test_lossMSE_t1 = criterion2(tp[0,:,:].to(device), tactile[context_frames:][0,:,:])\n",
    "        test_lossesMSE_t1 += test_lossMSE_t1.item() \n",
    "        test_lossMAE_t5 = criterion1(tp[4,:,:].to(device), tactile[context_frames:][4,:,:])\n",
    "        test_lossesMAE_t5 += test_lossMAE_t5.item() \n",
    "        test_lossMSE_t5 = criterion2(tp[4,:,:].to(device), tactile[context_frames:][4,:,:])\n",
    "        test_lossesMSE_t5 += test_lossMSE_t5.item() \n",
    "        test_lossMAE_t10 = criterion1(tp[9,:,:].to(device), tactile[context_frames:][9,:,:])\n",
    "        test_lossesMAE_t10 += test_lossMAE_t10.item() \n",
    "        test_lossMSE_t10 = criterion2(tp[9,:,:].to(device), tactile[context_frames:][9,:,:])\n",
    "        test_lossesMSE_t10 += test_lossMSE_t10.item() \n",
    "        \n",
    "        # calculate losses for specific forces\n",
    "        test_lossMAE_x = criterion1(tp[:,:,:16].to(device), tactile[context_frames:][:,:,:16])\n",
    "        test_lossesMAE_x += test_lossMAE_x.item() \n",
    "        test_lossMSE_x = criterion2(tp[:,:,:16].to(device), tactile[context_frames:][:,:,:16])\n",
    "        test_lossesMSE_x += test_lossMSE_x.item() \n",
    "        test_lossMAE_y = criterion1(tp[:,:,17:32].to(device), tactile[context_frames:][:,:,17:32])\n",
    "        test_lossesMAE_y += test_lossMAE_y.item() \n",
    "        test_lossMSE_y = criterion2(tp[:,:,17:32].to(device), tactile[context_frames:][:,:,17:32])\n",
    "        test_lossesMSE_y += test_lossMSE_y.item() \n",
    "        test_lossMAE_z = criterion1(tp[:,:,33:48].to(device), tactile[context_frames:][:,:,33:48])\n",
    "        test_lossesMAE_z += test_lossMAE_z.item() \n",
    "        test_lossMSE_z = criterion2(tp[:,:,33:48].to(device), tactile[context_frames:][:,:,33:48])\n",
    "        test_lossesMSE_z += test_lossMSE_z.item() \n",
    "\n",
    "        # calculate losses for specific timesteps and forces \n",
    "        test_lossMAE_x_ts1 = criterion1(tp[0,:,:16].to(device), tactile[context_frames:][0,:,:16])\n",
    "        test_lossesMAE_x_ts1 += test_lossMAE_x_ts1.item() \n",
    "        test_lossMSE_x_ts1 = criterion2(tp[0,:,:16].to(device), tactile[context_frames:][0,:,:16])\n",
    "        test_lossesMSE_x_ts1 += test_lossMSE_x_ts1.item() \n",
    "        test_lossMAE_y_ts1 = criterion1(tp[0,:,17:32].to(device), tactile[context_frames:][0,:,17:32])\n",
    "        test_lossesMAE_y_ts1 += test_lossMAE_y_ts1.item() \n",
    "        test_lossMSE_y_ts1 = criterion2(tp[0,:,17:32].to(device), tactile[context_frames:][0,:,17:32])\n",
    "        test_lossesMSE_y_ts1 += test_lossMSE_y_ts1.item() \n",
    "        test_lossMAE_z_ts1 = criterion1(tp[0,:,33:48].to(device), tactile[context_frames:][0,:,33:48])\n",
    "        test_lossesMAE_z_ts1 += test_lossMAE_z_ts1.item() \n",
    "        test_lossMSE_z_ts1 = criterion2(tp[0,:,33:48].to(device), tactile[context_frames:][0,:,33:48])\n",
    "        test_lossesMSE_z_ts1 += test_lossMSE_z_ts1.item() \n",
    " \n",
    "        test_lossMAE_x_ts5 = criterion1(tp[4,:,:16].to(device), tactile[context_frames:][4,:,:16])\n",
    "        test_lossesMAE_x_ts5 += test_lossMAE_x_ts5.item() \n",
    "        test_lossMSE_x_ts5 = criterion2(tp[4,:,:16].to(device), tactile[context_frames:][4,:,:16])\n",
    "        test_lossesMSE_x_ts5 += test_lossMSE_x_ts5.item() \n",
    "        test_lossMAE_y_ts5 = criterion1(tp[4,:,17:32].to(device), tactile[context_frames:][4,:,17:32])\n",
    "        test_lossesMAE_y_ts5 += test_lossMAE_y_ts5.item() \n",
    "        test_lossMSE_y_ts5 = criterion2(tp[4,:,17:32].to(device), tactile[context_frames:][4,:,17:32])\n",
    "        test_lossesMSE_y_ts5 += test_lossMSE_y_ts5.item() \n",
    "        test_lossMAE_z_ts5 = criterion1(tp[4,:,33:48].to(device), tactile[context_frames:][4,:,33:48])\n",
    "        test_lossesMAE_z_ts5 += test_lossMAE_z_ts5.item() \n",
    "        test_lossMSE_z_ts5 = criterion2(tp[4,:,33:48].to(device), tactile[context_frames:][4,:,33:48])\n",
    "        test_lossesMSE_z_ts5 += test_lossMSE_z_ts5.item() \n",
    "\n",
    "        test_lossMAE_x_ts10 = criterion1(tp[9,:,:16].to(device), tactile[context_frames:][9,:,:16])\n",
    "        test_lossesMAE_x_ts10 += test_lossMAE_x_ts10.item() \n",
    "        test_lossMSE_x_ts10 = criterion2(tp[9,:,:16].to(device), tactile[context_frames:][9,:,:16])\n",
    "        test_lossesMSE_x_ts10 += test_lossMSE_x_ts10.item() \n",
    "        test_lossMAE_y_ts10 = criterion1(tp[9,:,17:32].to(device), tactile[context_frames:][9,:,17:32])\n",
    "        test_lossesMAE_y_ts10 += test_lossMAE_y_ts10.item() \n",
    "        test_lossMSE_y_ts10 = criterion2(tp[9,:,17:32].to(device), tactile[context_frames:][9,:,17:32])\n",
    "        test_lossesMSE_y_ts10 += test_lossMSE_y_ts10.item() \n",
    "        test_lossMAE_z_ts10 = criterion1(tp[9,:,33:48].to(device), tactile[context_frames:][9,:,33:48])\n",
    "        test_lossesMAE_z_ts10 += test_lossMAE_z_ts10.item() \n",
    "        test_lossMSE_z_ts10 = criterion2(tp[9,:,33:48].to(device), tactile[context_frames:][9,:,33:48])\n",
    "        test_lossesMSE_z_ts10 += test_lossMSE_z_ts10.item()\n",
    "\n",
    "performance_data = []\n",
    "performance_data.append([\"test loss MAE(L1): \", (test_lossesMAE / index__)])\n",
    "performance_data.append([\"test loss MSE: \", (test_lossesMSE / index__)])\n",
    "performance_data.append([\"test loss MAE(L1) timestep 1: \", (test_lossesMAE_x / index__)])\n",
    "performance_data.append([\"test loss MSE timestep 1: \", (test_lossesMSE_x / index__)])\n",
    "performance_data.append([\"test loss MAE(L1) timestep 5: \", (test_lossesMAE_y / index__)])\n",
    "performance_data.append([\"test loss MSE timestep 5: \", (test_lossesMSE_y / index__)])\n",
    "performance_data.append([\"test loss MAE(L1) timestep 10: \", (test_lossesMAE_z / index__)])\n",
    "performance_data.append([\"test loss MSE timestep 10: \", (test_lossesMSE_z / index__)])\n",
    "performance_data.append([\"sheer x test loss MAE(L1): \", (test_lossesMAE_x / index__)])\n",
    "performance_data.append([\"sheer x test loss MSE: \", (test_lossesMSE_x / index__)])\n",
    "performance_data.append([\"sheer y test loss MAE(L1): \", (test_lossesMAE_y / index__)])\n",
    "performance_data.append([\"sheer y test loss MSE: \", (test_lossesMSE_y / index__)])\n",
    "performance_data.append([\"z test loss MAE(L1): \", (test_lossesMAE_z / index__)])\n",
    "performance_data.append([\"z test loss MSE: \", (test_lossesMSE_z / index__)])\n",
    "performance_data.append([\"sheer x test loss MAE(L1) timestep 1: \", (test_lossesMAE_x_ts1 / index__)])\n",
    "performance_data.append([\"sheer x test loss MSE timestep 1: \", (test_lossesMSE_x_ts1 / index__)])\n",
    "performance_data.append([\"sheer y test loss MAE(L1) timestep 1: \", (test_lossesMAE_y_ts1 / index__)])\n",
    "performance_data.append([\"sheer y test loss MSE timestep 1: \", (test_lossesMSE_y_ts1 / index__)])\n",
    "performance_data.append([\"z test loss MAE(L1) timestep 1: \", (test_lossesMAE_z_ts1 / index__)])\n",
    "performance_data.append([\"z test loss MSE timestep 1: \", (test_lossesMSE_z_ts1 / index__)])\n",
    "performance_data.append([\"sheer x test loss MAE(L1) timestep 5: \", (test_lossesMAE_x_ts5 / index__)])\n",
    "performance_data.append([\"sheer x test loss MSE timestep 5: \", (test_lossesMSE_x_ts5 / index__)])\n",
    "performance_data.append([\"sheer y test loss MAE(L1) timestep 5: \", (test_lossesMAE_y_ts5 / index__)])\n",
    "performance_data.append([\"sheer y test loss MSE timestep 5: \", (test_lossesMSE_y_ts5 / index__)])\n",
    "performance_data.append([\"z test loss MAE(L1) timestep 5: \", (test_lossesMAE_z_ts5 / index__)])\n",
    "performance_data.append([\"z test loss MSE timestep 5: \", (test_lossesMSE_z_ts5 / index__)])\n",
    "performance_data.append([\"sheer x test loss MAE(L1) timestep 10: \", (test_lossesMAE_x_ts10 / index__)])\n",
    "performance_data.append([\"sheer x test loss MSE timestep 10: \", (test_lossesMSE_x_ts10 / index__)])\n",
    "performance_data.append([\"sheer y test loss MAE(L1) timestep 10: \", (test_lossesMAE_y_ts10 / index__)])\n",
    "performance_data.append([\"sheer y test loss MSE timestep 10: \", (test_lossesMSE_y_ts10 / index__)])\n",
    "performance_data.append([\"z test loss MAE(L1) timestep 10: \", (test_lossesMAE_z_ts10 / index__)])\n",
    "performance_data.append([\"z test loss MSE timestep 10: \", (test_lossesMSE_z_ts10 / index__)])\n",
    "[print(i) for i in performance_data]\n",
    "\n",
    "np.save(model_path + 'performance_data', np.asarray(performance_data))\n",
    "\n",
    "# calculate tactile values for full sample:\n",
    "time_step_to_test_t1 = 0    # [batch_set, prediction frames(t1->tx)(6), batch_size, features(48)]\n",
    "time_step_to_test_t9 = 5\n",
    "predicted_data_t1 = []\n",
    "predicted_data_t9 = []\n",
    "groundtruth_data = []\n",
    "for index, batch_set in enumerate(tactile_predictions):\n",
    "    for batch in range(0, len(batch_set[0])):\n",
    "        prediction_values = batch_set[time_step_to_test_t1][batch]\n",
    "        predicted_data_t1.append(prediction_values)\n",
    "        prediction_values = batch_set[time_step_to_test_t9][batch]\n",
    "        predicted_data_t9.append(prediction_values)\n",
    "        gt_values = tactile_groundtruth[index][time_step_to_test_t1][batch]\n",
    "        groundtruth_data.append(gt_values)  \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-hometown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate tactile values for full sample:\n",
    "time_step_to_test_t1 = 0    # [batch_set, prediction frames(t1->tx)(6), batch_size, features(48)]\n",
    "time_step_to_test_t5 = 4\n",
    "time_step_to_test_t9 = 9\n",
    "predicted_data_t1 = []\n",
    "predicted_data_t5 = []\n",
    "predicted_data_t9 = []\n",
    "groundtruth_data = []\n",
    "experiment_to_test = 106\n",
    "for index, batch_set in enumerate(tactile_predictions):\n",
    "    for batch in range(0, len(batch_set[0])):\n",
    "        experiment = experiment_time_steps[index][0][batch]\n",
    "        if experiment == experiment_to_test:\n",
    "            prediction_values = batch_set[time_step_to_test_t1][batch]\n",
    "            predicted_data_t1.append(prediction_values)\n",
    "            prediction_values = batch_set[time_step_to_test_t5][batch]\n",
    "            predicted_data_t5.append(prediction_values)\n",
    "            prediction_values = batch_set[time_step_to_test_t9][batch]\n",
    "            predicted_data_t9.append(prediction_values)\n",
    "            gt_values = tactile_groundtruth[index][time_step_to_test_t1][batch]\n",
    "            groundtruth_data.append(gt_values)\n",
    "\n",
    "# print(tactile_predictions[0])\n",
    "# plt.plot([i for i in range(len(tactile_predictions[0]))], [i for i in range(len(tactile_predictions[0]))])\n",
    "plt.show()        \n",
    "mse_loss = torch.nn.MSELoss()\n",
    "# print(\"MAE timestep + 1: \", np.mean(np.asarray([mse_loss(np.asarray(pred.cpu().detach()), np.asarray(gt.cpu().detach()))  for pred, gt in zip(predicted_data_t1, groundtruth_data)])))\n",
    "# print(\"MAE timestep + 5: \", mse_loss(torch.tensor(predicted_data_t5), torch.tensor(groundtruth_data)))\n",
    "# print(\"MAE timestep + 9: \", mse_loss(torch.tensor(predicted_data_t9), torch.tensor(groundtruth_data)))\n",
    "\n",
    "model_path = \"/home/user/Robotics/slip_detection_model/slip_detection_model/manual_data_models/models/simple_model_001/\"\n",
    "# test data\n",
    "index = 0\n",
    "titles = [\"sheerx\", \"sheery\", \"normal\"]\n",
    "for j in range(3):\n",
    "    for i in range(16):\n",
    "        groundtruth_taxle = []\n",
    "        predicted_taxel = []\n",
    "        predicted_taxel_t1 = []\n",
    "        predicted_taxel_t5 = []\n",
    "        predicted_taxel_t9 = []\n",
    "        # good = 140, 145 (lifting up the )\n",
    "        for k in range(len(predicted_data_t1)):#310, 325):#len(predicted_data_t1)):  # add in length of context data\n",
    "            predicted_taxel_t1.append(predicted_data_t1[k][j+i].cpu().detach().numpy())\n",
    "            predicted_taxel_t5.append(predicted_data_t5[k][j+i].cpu().detach().numpy())\n",
    "            predicted_taxel_t9.append(predicted_data_t9[k][j+i].cpu().detach().numpy())\n",
    "            groundtruth_taxle.append(groundtruth_data[k][j+i].cpu().detach().numpy())\n",
    "\n",
    "        index += 1\n",
    "        fig, ax1 = plt.subplots()\n",
    "        ax1.set_xlabel('time step')\n",
    "        ax1.set_ylabel('tactile reading')\n",
    "        ax1.plot(predicted_taxel_t1, alpha=0.5, c=\"b\", label=\"t1\")\n",
    "        ax1.plot(predicted_taxel_t5, alpha=0.5, c=\"k\", label=\"t5\")\n",
    "        ax1.plot(predicted_taxel_t9, alpha=0.5, c=\"g\", label=\"t10\")\n",
    "        ax1.plot(groundtruth_taxle, alpha=0.5, c=\"r\", label=\"gt\")\n",
    "        ax1.tick_params(axis='y')\n",
    "        ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "        ax2.set_ylabel('loss')  # we already handled the x-label with ax1\n",
    "        ax2.plot([i for i in range(len(groundtruth_data))], [mse_loss(predicted_data_t9[i], groundtruth_data[i]) for i in range(len(groundtruth_data))], alpha=0.5)\n",
    "        fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "        fig.subplots_adjust(top=0.90)\n",
    "        ax1.legend(loc=\"upper right\")\n",
    "        plt.title(\"Simple_LSTM tactile \" + str(index))\n",
    "        plt.savefig(model_path + '/' + str(experiment_to_test) + '/sample_test_with_loss_' + str(index) + '.png', dpi=300)\n",
    "        plt.show()\n",
    "\n",
    "        fig, ax1 = plt.subplots()\n",
    "        ax1.set_xlabel('time step')\n",
    "        ax1.set_ylabel('tactile reading')\n",
    "        ax1.plot(predicted_taxel_t1, alpha=0.5, c=\"b\", label=\"t1\")\n",
    "        ax1.plot(groundtruth_taxle, alpha=0.5, c=\"r\", label=\"gt\")\n",
    "        ax1.tick_params(axis='y')\n",
    "        ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "        ax2.set_ylabel('loss')  # we already handled the x-label with ax1\n",
    "        ax2.plot([i for i in range(len(groundtruth_data))], [mse_loss(predicted_data_t9[i], groundtruth_data[i]) for i in range(len(groundtruth_data))], alpha=0.5)\n",
    "        fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "        fig.subplots_adjust(top=0.90)\n",
    "        ax1.legend(loc=\"upper right\")\n",
    "        plt.title(\"Simple_LSTM tactile \" + str(index))\n",
    "        plt.savefig(model_path + '/' + str(experiment_to_test) + '/T0sample_test_with_loss_' + str(index) + '.png', dpi=300)\n",
    "        plt.show()\n",
    "        \n",
    "        fig, ax1 = plt.subplots()\n",
    "        ax1.set_xlabel('time step')\n",
    "        ax1.set_ylabel('tactile reading')\n",
    "        ax1.plot(predicted_taxel_t5, alpha=0.5, c=\"b\", label=\"t5\")\n",
    "        ax1.plot(groundtruth_taxle, alpha=0.5, c=\"r\", label=\"gt\")\n",
    "        ax1.tick_params(axis='y')\n",
    "        ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "        ax2.set_ylabel('loss')  # we already handled the x-label with ax1\n",
    "        ax2.plot([i for i in range(len(groundtruth_data))], [mse_loss(predicted_data_t9[i], groundtruth_data[i]) for i in range(len(groundtruth_data))], alpha=0.5)\n",
    "        fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "        fig.subplots_adjust(top=0.90)\n",
    "        ax1.legend(loc=\"upper right\")\n",
    "        plt.title(\"Simple_LSTM tactile \" + str(index))\n",
    "        plt.savefig(model_path + '/' + str(experiment_to_test) + '/T5sample_test_with_loss_' + str(index) + '.png', dpi=300)\n",
    "        plt.show()\n",
    "            \n",
    "        fig, ax1 = plt.subplots()\n",
    "        ax1.set_xlabel('time step')\n",
    "        ax1.set_ylabel('tactile reading')\n",
    "        ax1.plot(predicted_taxel_t9, alpha=0.5, c=\"b\", label=\"t10\")\n",
    "        ax1.plot(groundtruth_taxle, alpha=0.5, c=\"r\", label=\"gt\")\n",
    "        ax1.tick_params(axis='y')\n",
    "        ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "        ax2.set_ylabel('loss')  # we already handled the x-label with ax1\n",
    "        ax2.plot([i for i in range(len(groundtruth_data))], [mse_loss(predicted_data_t9[i], groundtruth_data[i]) for i in range(len(groundtruth_data))], alpha=0.5)\n",
    "        fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "        fig.subplots_adjust(top=0.90)\n",
    "        ax1.legend(loc=\"upper right\")\n",
    "        plt.title(\"Simple_LSTM tactile \" + str(index))\n",
    "        plt.savefig(model_path + '/' + str(experiment_to_test) + '/T10sample_test_with_loss_' + str(index) + '.png', dpi=300)\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

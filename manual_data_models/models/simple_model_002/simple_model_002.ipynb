{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "capable-composite",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import csv\n",
    "import tqdm\n",
    "import copy\n",
    "import click\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from string import digits\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "seed = 42\n",
    "epochs = 200\n",
    "batch_size = 32\n",
    "learning_rate = 1e-3\n",
    "context_frames = 10\n",
    "sequence_length = 16\n",
    "lookback = sequence_length\n",
    "\n",
    "context_epochs = 20\n",
    "context_batch_size = 1\n",
    "context_learning_rate = 1e-3\n",
    "context_data_length = 20\n",
    "\n",
    "valid_train_split = 0.8  # precentage of train data from total\n",
    "test_train_split = 0.9  # precentage of train data from total\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")#  use gpu if available\n",
    "################################# CHANGE THIS!!!!  #################################\n",
    "model_path = \"/home/user/Robotics/slip_detection_model/slip_detection_model/manual_data_models/models/simple_model_002/\"\n",
    "################################# CHANGE THIS!!!!  #################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "appropriate-transformation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator:\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "        data_map = []\n",
    "        with open(data_dir + 'map.csv', 'r') as f:  # rb\n",
    "            reader = csv.reader(f)\n",
    "            for row in reader:\n",
    "                data_map.append(row)\n",
    "\n",
    "        if len(data_map) <= 1: # empty or only header\n",
    "            print(\"No file map found\")\n",
    "            exit()\n",
    "\n",
    "        self.data_map = data_map\n",
    "\n",
    "    def load_full_data(self):\n",
    "        dataset_train = FullDataSet(self.data_dir, self.data_map, type_=\"train\")\n",
    "        dataset_valid = FullDataSet(self.data_dir, self.data_map, type_=\"valid\")\n",
    "        dataset_test = FullDataSet(self.data_dir, self.data_map, type_=\"test\")\n",
    "        transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "        train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "        valid_loader = torch.utils.data.DataLoader(dataset_valid, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=False)\n",
    "        return train_loader, valid_loader, test_loader\n",
    "\n",
    "\n",
    "class FullDataSet():\n",
    "    def __init__(self, data_dir, data_map, type_=\"train\"):\n",
    "        dataset_full = []\n",
    "        for index, value in enumerate(data_map[1:]):  # ignore header\n",
    "            robot = np.load(data_dir + value[0])\n",
    "            xela1 = np.load(data_dir + value[1])\n",
    "            xela2 = np.load(data_dir + value[2])\n",
    "            experiment = np.load(data_dir + value[-2])\n",
    "            time_step  = np.load(data_dir + value[-1])\n",
    "            for i in range(len(robot)):\n",
    "                dataset_full.append([robot[i].astype(np.float32),\n",
    "                                     xela1[i].astype(np.float32),\n",
    "                                     xela2[i].astype(np.float32),\n",
    "                                     experiment[i],\n",
    "                                     time_step[i]])\n",
    "        if type_ == \"train\":\n",
    "            self.samples = dataset_full[0:int(len(dataset_full)*test_train_split)]\n",
    "        elif type_ == \"valid\":\n",
    "            self.samples = dataset_full[int(len(dataset_full)*(valid_train_split)):int(len(dataset_full)*test_train_split)]\n",
    "        elif type_ == \"test\":\n",
    "            self.samples = dataset_full[int(len(dataset_full)*test_train_split):-1]\n",
    "\n",
    "        data_map = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return(self.samples[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "raised-remainder",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FullModel, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(96, 96).to(device)  # tactile\n",
    "        self.lstm2 = nn.LSTM(6, 6).to(device)  # pos_vel\n",
    "        self.fc1 = nn.Linear(96+6, 96)  # tactile + pos_vel\n",
    "        self.lstm3 = nn.LSTM(96, 96).to(device)  # pos_vel\n",
    "\n",
    "    def forward(self, tactiles, actions):\n",
    "        state = actions[0]\n",
    "        state.to(device)\n",
    "        batch_size__ = tactiles.shape[1]\n",
    "        outputs = []\n",
    "        hidden1 = (torch.rand(1,batch_size__,96).to(device), torch.rand(1,batch_size__,96).to(device))\n",
    "        hidden2 = (torch.rand(1,batch_size__,6).to(device), torch.rand(1,batch_size__,6).to(device))\n",
    "        hidden3 = (torch.rand(1,batch_size__,96).to(device), torch.rand(1,batch_size__,96).to(device))\n",
    "        for index, (sample_tactile, sample_action) in enumerate(zip(tactiles.squeeze(), actions.squeeze())):\n",
    "            sample_tactile.to(device)\n",
    "            sample_action.to(device)\n",
    "            # 2. Run through lstm:\n",
    "            if index > context_frames-1:\n",
    "                out1, hidden1 = self.lstm1(out4, hidden1)\n",
    "                out2, hidden2 = self.lstm2(sample_action.unsqueeze(0), hidden2)\n",
    "                robot_and_tactile = torch.cat((out2.squeeze(), out1.squeeze()), 1)\n",
    "                out3 = self.fc1(robot_and_tactile.unsqueeze(0).cpu().detach())\n",
    "                out4, hidden3 = self.lstm3(out3.to(device), hidden3)\n",
    "                outputs.append(out4.squeeze())\n",
    "            else:\n",
    "                out1, hidden1 = self.lstm1(sample_tactile.unsqueeze(0), hidden1)\n",
    "                out2, hidden2 = self.lstm2(sample_action.unsqueeze(0), hidden2)\n",
    "                robot_and_tactile = torch.cat((out2.squeeze(), out1.squeeze()), 1)\n",
    "                out3 = self.fc1(robot_and_tactile.unsqueeze(0).cpu().detach())\n",
    "                out4, hidden3 = self.lstm3(out3.to(device), hidden3)\n",
    "\n",
    "        return torch.stack(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "temporal-newton",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "        self.train_full_loader, self.valid_full_loader, self.test_full_loader = BG.load_full_data()\n",
    "        self.full_model = FullModel()\n",
    "        self.criterion = nn.L1Loss()\n",
    "        self.optimizer = optim.Adam(self.full_model.parameters(), lr=learning_rate)\n",
    "\n",
    "    def train_full_model(self):\n",
    "        best_model_loss_score = 10.0 \n",
    "        self.plot_training_loss = []\n",
    "        self.plot_validation_loss = []\n",
    "        previous_val_mean_loss = 1.0\n",
    "        early_stop_clock = 0\n",
    "        progress_bar = tqdm.tqdm(range(0, epochs), total=(epochs*len(self.train_full_loader)))\n",
    "        mean_test = 0\n",
    "        for epoch in progress_bar:\n",
    "            loss = 0\n",
    "            losses = 0.0\n",
    "            for index, batch_features in enumerate(self.train_full_loader):\n",
    "                action   = batch_features[0].permute(1,0,2).to(device)\n",
    "                tactile1 = batch_features[1].permute(1,0,2).to(device)\n",
    "                tactile2 = batch_features[1].permute(1,0,2).to(device)\n",
    "                tactile  = torch.dstack((tactile1,tactile2))\n",
    "                tactile_predictions = self.full_model.forward(tactiles=tactile, actions=action) # Step 3. Run our forward pass.\n",
    "                self.optimizer.zero_grad()\n",
    "                loss = self.criterion(tactile_predictions.to(device), tactile[context_frames:])\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                losses += loss.item()\n",
    "                if index:\n",
    "                    mean = losses / index\n",
    "                else:\n",
    "                    mean = 0\n",
    "                progress_bar.set_description(\"epoch: {}, \".format(epoch) + \"loss: {:.4f}, \".format(float(loss.item())) + \"mean loss: {:.4f}, \".format(mean))\n",
    "                progress_bar.update()\n",
    "            self.plot_training_loss.append(mean)\n",
    "\n",
    "            val_losses = 0.0\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for index__, batch_features in enumerate(self.valid_full_loader):\n",
    "                    action = batch_features[0].permute(1,0,2).to(device)\n",
    "                    tactile1 = batch_features[1].permute(1,0,2).to(device)\n",
    "                    tactile2 = batch_features[1].permute(1,0,2).to(device)\n",
    "                    tactile  = torch.dstack((tactile1,tactile2))\n",
    "                    tactile_predictions = self.full_model.forward(tactiles=tactile, actions=action)  # Step 3. Run our forward pass.\n",
    "                    self.optimizer.zero_grad()\n",
    "                    val_loss = self.criterion(tactile_predictions.to(device), tactile[context_frames:])\n",
    "                    val_losses += val_loss.item()\n",
    "\n",
    "            print(\"Validation mean loss: {:.4f}, \".format(val_losses / index__))\n",
    "            self.plot_validation_loss.append(val_losses / index__)\n",
    "            if previous_val_mean_loss < val_losses / index__:\n",
    "                early_stop_clock +=1\n",
    "                previous_val_mean_loss = val_losses / index__ \n",
    "                if early_stop_clock == 3:\n",
    "                    print(\"Early stopping\")\n",
    "                    break\n",
    "            else:\n",
    "                if (val_losses / index__) < best_model_loss_score:\n",
    "                    self.strongest_model = copy.deepcopy(self.full_model)\n",
    "                early_stop_clock = 0\n",
    "                previous_val_mean_loss = val_losses / index__\n",
    "        plt.plot(self.plot_training_loss, c=\"r\", label=\"train loss MAE\")\n",
    "        plt.plot(self.plot_validation_loss, c='b', label=\"val loss MAE\")\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        plt.show()\n",
    "        plt.savefig(model_path + '/model_training_plot.png', dpi=300)\n",
    "        np.save(model_path + 'training_loss', np.asarray(self.plot_training_loss))\n",
    "        np.save(model_path + 'validation_loss', np.asarray(self.plot_validation_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "hourly-capability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/home/user/Robotics/Data_sets/slip_detection/manual_slip_detection/'\n",
    "BG = BatchGenerator(data_dir)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "irish-adapter",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 0.0353, mean loss: 0.0426, :   2%|▏         | 2849/142100 [01:15<9:18:09,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0380, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 2, loss: 0.0358, mean loss: 0.0378, :   4%|▍         | 5691/142100 [02:23<6:43:43,  5.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0301, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 3, loss: 0.0236, mean loss: 0.0334, :   6%|▌         | 8535/142100 [03:37<9:55:05,  3.74it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0254, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 4, loss: 0.0278, mean loss: 0.0308, :   8%|▊         | 11378/142100 [04:48<8:41:34,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0256, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 5, loss: 0.0260, mean loss: 0.0328, :  10%|█         | 14221/142100 [05:56<6:14:17,  5.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0241, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 6, loss: 0.0273, mean loss: 0.0323, :  12%|█▏        | 17062/142100 [07:03<8:22:11,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0234, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 7, loss: 0.0220, mean loss: 0.0284, :  14%|█▍        | 19905/142100 [08:11<5:46:44,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0211, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 8, loss: 0.0274, mean loss: 0.0300, :  16%|█▌        | 22746/142100 [09:18<8:11:47,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0218, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 9, loss: 0.0235, mean loss: 0.0287, :  18%|█▊        | 25588/142100 [10:25<5:42:39,  5.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0208, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 10, loss: 0.0215, mean loss: 0.0282, :  20%|██        | 28429/142100 [11:34<9:51:24,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0219, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 11, loss: 0.0230, mean loss: 0.0285, :  22%|██▏       | 31273/142100 [12:47<5:47:07,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0212, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 12, loss: 0.0209, mean loss: 0.0265, :  24%|██▍       | 34114/142100 [14:03<6:35:00,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0201, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 13, loss: 0.0229, mean loss: 0.0248, :  26%|██▌       | 36957/142100 [15:15<5:09:11,  5.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0201, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 14, loss: 0.0196, mean loss: 0.0272, :  28%|██▊       | 39798/142100 [16:23<7:23:47,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0197, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 15, loss: 0.0211, mean loss: 0.0260, :  30%|███       | 42641/142100 [17:37<5:47:49,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0206, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 16, loss: 0.0325, mean loss: 0.0258, :  32%|███▏      | 45482/142100 [18:46<6:23:37,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0186, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 17, loss: 0.0233, mean loss: 0.0273, :  34%|███▍      | 48324/142100 [19:53<4:35:51,  5.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0187, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 18, loss: 0.0246, mean loss: 0.0251, :  36%|███▌      | 51166/142100 [21:00<6:05:25,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0180, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 19, loss: 0.0216, mean loss: 0.0246, :  38%|███▊      | 54008/142100 [22:07<4:13:52,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0181, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 20, loss: 0.0204, mean loss: 0.0268, :  40%|████      | 56850/142100 [23:17<5:14:55,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0195, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 21, loss: 0.0206, mean loss: 0.0241, :  42%|████▏     | 59693/142100 [24:33<5:23:13,  4.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0181, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 22, loss: 0.0230, mean loss: 0.0263, :  44%|████▍     | 62534/142100 [25:45<4:14:13,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0184, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 23, loss: 0.0218, mean loss: 0.0265, :  46%|████▌     | 65376/142100 [26:57<5:26:48,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0178, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 24, loss: 0.0249, mean loss: 0.0254, :  48%|████▊     | 68219/142100 [28:10<3:46:34,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0187, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 25, loss: 0.0217, mean loss: 0.0265, :  50%|█████     | 71060/142100 [29:19<3:31:10,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0177, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 26, loss: 0.0268, mean loss: 0.0244, :  52%|█████▏    | 73902/142100 [30:28<5:10:37,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0190, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 27, loss: 0.0271, mean loss: 0.0262, :  54%|█████▍    | 76745/142100 [31:37<4:19:49,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0191, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 28, loss: 0.0254, mean loss: 0.0268, :  56%|█████▌    | 79586/142100 [32:46<3:01:24,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0185, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 29, loss: 0.0181, mean loss: 0.0247, :  58%|█████▊    | 82428/142100 [33:57<3:08:14,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0181, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 30, loss: 0.0217, mean loss: 0.0276, :  60%|██████    | 85270/142100 [35:12<3:20:57,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0183, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 31, loss: 0.0188, mean loss: 0.0275, :  62%|██████▏   | 88110/142100 [36:31<10:18:45,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0173, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 32, loss: 0.0196, mean loss: 0.0234, :  64%|██████▍   | 90954/142100 [37:51<2:44:37,  5.18it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0172, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 33, loss: 0.0182, mean loss: 0.0244, :  66%|██████▌   | 93797/142100 [39:05<2:27:13,  5.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0175, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 34, loss: 0.0203, mean loss: 0.0239, :  68%|██████▊   | 96639/142100 [40:13<2:15:16,  5.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0180, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 35, loss: 0.0186, mean loss: 0.0227, :  70%|███████   | 99481/142100 [41:19<2:49:07,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0174, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 36, loss: 0.0215, mean loss: 0.0249, :  72%|███████▏  | 102323/142100 [42:24<1:52:42,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0169, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 37, loss: 0.0196, mean loss: 0.0232, :  74%|███████▍  | 105165/142100 [43:29<1:45:06,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0170, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 38, loss: 0.0244, mean loss: 0.0226, :  76%|███████▌  | 108008/142100 [44:34<1:37:47,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0180, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 39, loss: 0.0188, mean loss: 0.0229, :  78%|███████▊  | 110849/142100 [45:40<1:28:01,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0166, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 40, loss: 0.0205, mean loss: 0.0242, :  80%|████████  | 113691/142100 [46:45<1:52:04,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0176, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 41, loss: 0.0225, mean loss: 0.0243, :  82%|████████▏ | 116533/142100 [47:51<1:12:21,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0179, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 42, loss: 0.0201, mean loss: 0.0241, :  84%|████████▍ | 119375/142100 [49:07<1:08:37,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0173, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 43, loss: 0.0222, mean loss: 0.0250, :  86%|████████▌ | 122218/142100 [50:20<1:03:20,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0169, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 44, loss: 0.0220, mean loss: 0.0231, :  88%|████████▊ | 125059/142100 [51:32<1:07:46,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0171, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 45, loss: 0.0172, mean loss: 0.0245, :  90%|█████████ | 127899/142100 [52:57<1:07:53,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0169, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 46, loss: 0.0203, mean loss: 0.0220, :  92%|█████████▏| 130744/142100 [54:17<37:24,  5.06it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0168, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 47, loss: 0.0175, mean loss: 0.0246, :  94%|█████████▍| 133585/142100 [55:25<24:44,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0178, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 48, loss: 0.0165, mean loss: 0.0226, :  96%|█████████▌| 136427/142100 [56:32<16:46,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0166, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 49, loss: 0.0229, mean loss: 0.0232, :  98%|█████████▊| 139269/142100 [57:39<08:25,  5.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0170, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 49, loss: 0.0182, mean loss: 0.0202, :   0%|          | 50/142100 [58:46<2782:52:55, 70.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.0161, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA1DElEQVR4nO3deXxV1bXA8d8ihAQCBAgIFJAgYJVJlIC0DE4VEZHhIQLFBxUr+rQOValxomqlSrXCo2orVhRRA4jyQEFxKuJIAYUKToQIElQIQ4AIgQzr/bHPTW7CDbkZb8hZ38/nfO695+yz7z4azrp7OHuLqmKMMcZ/6kS6AMYYYyLDAoAxxviUBQBjjPEpCwDGGONTFgCMMcan6ka6AGXRvHlzTUxMjHQxjDHmhLJu3brdqtqi+P4TKgAkJiaydu3aSBfDGGNOKCKyLdR+awIyxhifsgBgjDE+ZQHAGGN86oTqAzDGREZOTg7p6elkZ2dHuijmOGJjY2nbti3R0dFhpbcAYIwpVXp6Oo0aNSIxMRERiXRxTAiqyp49e0hPT6dDhw5hnWNNQMaYUmVnZ5OQkGA3/xpMREhISChTLc0CgDEmLHbzr/nK+v/IHwHgscdgwYJIl8IYY2oUfwSA2bNh/vxIl8IYU06ZmZk88cQT5Tp3yJAhZGZmhp3+3nvv5ZFHHinXd5VGRLjiiisKPufm5tKiRQuGDh1aJN2IESPo27fvMeVq06YNPXv2LNjKcl2h+CMANGkCFfwPZYyJnOMFgNzc3OOeu3z5cpo0aVIFpSq7uLg4Nm7cyOHDhwF46623aNOmTZE0mZmZrFu3jv3795OWllbk2O9//3vWr19fsFX0uvwRAOLjYf/+SJfCGFNOycnJbNmyhZ49ezJlyhRWrlzJgAEDGDZsGF26dAHcr+ZevXrRtWtXZs+eXXBuYmIiu3fvZuvWrZx++ulcffXVdO3alUGDBhXciEuyfv16+vbtS48ePRg5ciT79u0DYNasWXTp0oUePXowduxYAN57772CX+ZnnnkmBw8eDJnnkCFDWLZsGQApKSmMGzeuyPFXXnmFSy+9lLFjxzK/ilsu/DEMtEkT2LQp0qUwpna4+WZYv75y8+zZE2bOLPHwQw89xMaNG1nvfe/KlSv59NNP2bhxY8GQxzlz5tCsWTMOHz5M7969GTVqFAkJCUXy2bx5MykpKTz11FNcfvnlvPzyy0WaZIqbMGECf/vb3zjnnHOYOnUq9913HzNnzuShhx7i22+/JSYmpqAZ5pFHHuHxxx+nX79+ZGVlERsbGzLPsWPHcv/99zN06FD+85//MGnSJN5///2C4ykpKUydOpWWLVsyatQo7rzzzoJjM2bM4PnnnwegadOm/Otf/yqx7OGwGoAx5oTUp0+fIuPdZ82axRlnnEHfvn3Zvn07mzdvPuacDh060LNnTwB69erF1q1bS8x///79ZGZmcs455wAwceJEVq1aBUCPHj0YP348zz//PHXrut/R/fr145ZbbmHWrFlkZmYW7C+uR48ebN26lZSUFIYMGVLk2M6dO9m8eTP9+/fn1FNPJTo6mo0bNxYcD24CqujNH/xUA9i/H1TBhrIZUzHH+aVeneLi4grer1y5krfffpuPP/6YBg0acO6554YcDx8TE1PwPioqqtQmoJIsW7aMVatW8eqrrzJt2jQ+//xzkpOTueSSS1i+fDn9+vVjxYoVnHbaaSHPHzZsGLfddhsrV65kz549BfsXLlzIvn37CgLbgQMHSElJYdq0aeUqZ2n8UwPIy4Offop0SYwx5dCoUaMS29TB/Vpv2rQpDRo04KuvvuKTTz6p8HfGx8fTtGnTguaZefPmcc4555Cfn8/27ds577zzmD59Ovv37ycrK4stW7bQvXt3br/9dnr37s1XX31VYt6TJk3ij3/8I927dy+yPyUlhTfeeIOtW7eydetW1q1bV6X9AGEFABEZLCJfi0iqiCSHOB4jIgu846tFJNHbnygih0Vkvbf9I+icXiLyuXfOLKnKp0wCPeU2EsiYE1JCQgL9+vWjW7duTJky5ZjjgwcPJjc3l9NPP53k5ORjhlCW19y5c5kyZQo9evRg/fr1TJ06lby8PK644gq6d+/OmWeeyY033kiTJk2YOXMm3bp1o0ePHkRHR3PxxReXmG/btm258cYbi+zbunUr27ZtK1L2Dh06EB8fz+rVqwHXBxA8DPR4TVjhEFU9fgKRKOAb4EIgHVgDjFPVL4LSXAf0UNVrRWQsMFJVx3iB4DVV7RYi338DNwKrgeXALFV9/XhlSUpK0nItCPPSS3D55bBxI3TtWvbzjfG5L7/8ktNPPz3SxTBhCPX/SkTWqWpS8bTh1AD6AKmqmqaqR4H5wPBiaYYDc733i4ALjveLXkRaA41V9RN1Eeg5YEQYZSmf+Hj3ajUAY4wpEE4AaANsD/qc7u0LmUZVc4H9QGD8VQcR+UxE3hORAUHp00vJEwARmSwia0VkbUZGRhjFDcGagIwx5hhV3Qn8A3Cyqp4J3AK8KCKNy5KBqs5W1SRVTWrR4pg1jcMTqAHYUFBjjCkQTgDYAbQL+tzW2xcyjYjUBeKBPap6RFX3AKjqOmALcKqXvm0peVYeqwEYY8wxwgkAa4DOItJBROoBY4GlxdIsBSZ67y8D3lVVFZEWXicyInIK0BlIU9UfgAMi0tfrK5gALKmE6wnNagDGGHOMUh8EU9VcEfkdsAKIAuao6iYRuR9Yq6pLgaeBeSKSCuzFBQmAgcD9IpID5APXqupe79h1wLNAfeB1b6sasbEQE2M1AGOMCRJWH4CqLlfVU1W1o6pO8/ZN9W7+qGq2qo5W1U6q2kdV07z9L6tqV1XtqapnqeqrQXmuVdVuXp6/09LGo1aUTQdhjK80bNiwTPsr6t5770VESE1NLdg3c+ZMRITg4evr169HRHjjjTeKnB8VFVVkjP9DDz1UJeUM5o+pIMCmhDbGVLnu3bszf/587r77bgBeeukluhZ79iglJYX+/fuTkpLC4MGDC/bXr1+/YLK76uKPqSCgcD4gY8wJJzk5mccff7zgc2DRlqysLC644ALOOussunfvzpIl4XclqipTpkyhW7dudO/enQXeqoE//PADAwcOpGfPnnTr1o3333+fvLw8fvOb3xSknTFjRsg8R4wYUVCGLVu2EB8fT/PmzYt850svvcSzzz7LW2+9Vab1e6uCf2oA8fFWAzCmEkRgNmjGjBnDzTffzPXXXw+4SdNWrFhBbGwsixcvpnHjxuzevZu+ffsybNiwsNbGfeWVV1i/fj0bNmxg9+7d9O7dm4EDB/Liiy9y0UUXcdddd5GXl8ehQ4dYv349O3bsKJiZs6SVuBo3bky7du3YuHEjS5YsYcyYMTzzzDMFxz/66CM6dOhAx44dOffcc1m2bBmjRo0C4PDhwwUzlQLccccdjBkzptTrqAj/BIAmTSA9vdRkxpia58wzz2TXrl18//33ZGRk0LRpU9q1a0dOTg533nknq1atok6dOuzYsYOdO3fSqlWrUvP84IMPGDduHFFRUbRs2ZJzzjmHNWvW0Lt3byZNmkROTg4jRoygZ8+enHLKKaSlpXHDDTdwySWXMGjQoBLzDSzksmLFCt55550iASAlJaVgAZmxY8fy3HPPFQSASDQB+ScAWA3AmEoRqdmgR48ezaJFi/jxxx8Lfhm/8MILZGRksG7dOqKjo0lMTKxws8rAgQNZtWoVy5Yt4ze/+Q233HILEyZMYMOGDaxYsYJ//OMfLFy4kDlz5oQ8f+jQoUyZMoWkpCQaNy587jUvL4+XX36ZJUuWMG3aNFSVPXv2cPDgQRo1alShMpeXv/oALAAYc8IaM2YM8+fPZ9GiRYwePRpw00CfdNJJREdH869//Ytt27aFnd+AAQNYsGABeXl5ZGRksGrVKvr06cO2bdto2bIlV199Nb/97W/59NNP2b17N/n5+YwaNYoHHniATz/9tMR8GzRowPTp07nrrruK7H/nnXfo0aMH27dvL5j5c9SoUSxevLh8/0Eqgb9qAIcPw9GjUK9epEtjjCmjrl27cvDgQdq0aUPr1q0BGD9+PJdeeindu3cnKSmpxAVYQhk5ciQff/wxZ5xxBiLCX/7yF1q1asXcuXN5+OGHiY6OpmHDhjz33HPs2LGDK6+8kvz8fAAefPDB4+YdaOYJlpKSwsiRI4vsGzVqFH//+9+ZMGHCMX0AgwcPrvKhoKVOB12TlHs6aIDHHoMbboBdu6C8cwoZ41M2HfSJo7Kng64dbDoIY4wpwj8BwCaEM8aYIvwTAKwGYEyFnEjNxX5V1v9H/gkAVgMwptxiY2PZs2ePBYEaLDCsNDY2Nuxz/DMKKBAArAZgTJm1bduW9PR0yr0qn6kWsbGxtG3btvSEHv8EAFsX2Jhyi46OpkOHDpEuhqlk/mkCatQIRKwGYIwxHv8EgDp1oHFjqwEYY4zHPwEAbDoIY4wJ4q8AYKuCGWNMAX8FAKsBGGNMgbACgIgMFpGvRSRVRJJDHI8RkQXe8dUikljs+MkikiUitwXt2yoin4vIehEp5wQ/ZWQ1AGOMKVBqABCRKOBx4GKgCzBORLoUS3YVsE9VOwEzgOnFjj8KvB4i+/O8BeOPmaSoSlgNwBhjCoRTA+gDpKpqmqoeBeYDw4ulGQ7M9d4vAi4Qb002ERkBfAtsqpQSV4TVAIwxpkA4AaANsD3oc7q3L2QaVc0F9gMJItIQuB24L0S+CrwpIutEZHJJXy4ik0VkrYisrfBTiIGF4e1xdmOMqfJO4HuBGaqaFeJYf1U9C9e0dL2IDAyVgarOVtUkVU1qUdF5/Js0gfx8yApVHGOM8ZdwpoLYAbQL+tzW2xcqTbqI1AXigT3A2cBlIvIXoAmQLyLZqvqYqu4AUNVdIrIY19S0qiIXU6rg6SAitAanMcbUFOHUANYAnUWkg4jUA8YCS4ulWQpM9N5fBryrzgBVTVTVRGAm8GdVfUxE4kSkEYCIxAGDgI0Vv5xS2IRwxhhToNQagKrmisjvgBVAFDBHVTeJyP3AWlVdCjwNzBORVGAvLkgcT0tgsddPXBd4UVXfqMB1hMcmhDPGmAJhzQaqqsuB5cX2TQ16nw2MLiWPe4PepwFnlKWglcLWBDDGmAL+ehLYVgUzxpgC/goAVgMwxpgC/goAVgMwxpgC/goAMTEQG2s1AGOMwW8BAGw6CGOM8fgvANiEcMYYA/g1AFgNwBhjfBgA4uOtBmCMMfgxAFgNwBhjAD8GAKsBGGMM4McAYJ3AxhgD+DEAxMdDdjYcORLpkhhjTET5LwDYlNDGGAP4MQDYdBDGGAP4MQDYhHDGGAP4MQBYDcAYYwA/BgCrARhjDODnAGA1AGOMz4UVAERksIh8LSKpIpIc4niMiCzwjq8WkcRix08WkSwRuS3cPKuMrQtsjDFAGAFARKKAx4GLgS7AOBHpUizZVcA+Ve0EzACmFzv+KPB6GfOsGg0bQp06VgMwxvheODWAPkCqqqap6lFgPjC8WJrhwFzv/SLgAhERABEZAXwLbCpjnlWjTh1o3NhqAMYY3wsnALQBtgd9Tvf2hUyjqrnAfiBBRBoCtwP3lSPPqmPTQRhjTJV3At8LzFDVrPJmICKTRWStiKzNyMionFLZqmDGGEPdMNLsANoFfW7r7QuVJl1E6gLxwB7gbOAyEfkL0ATIF5FsYF0YeQKgqrOB2QBJSUkaRnlLZzUAY4wJKwCsATqLSAfcTXos8OtiaZYCE4GPgcuAd1VVgQGBBCJyL5Clqo95QaK0PKtOfDxs21ZtX2eMMTVRqU1AXpv+74AVwJfAQlXdJCL3i8gwL9nTuDb/VOAW4LjDOkvKs/yXUUZWAzDGmLBqAKjqcmB5sX1Tg95nA6NLyePe0vKsNtYHYIwxPnwSGAqXhczPj3RJjDEmYvwbAFQhq9yDk4wx5oTnzwBg00EYY4xPA4BNCGeMMf4JADk5QR+sBmCMMf4IAD17wqRJQTtsTQBjjPFHAEhIgNTUoB22KpgxxvgjAHTqBJs3B+2wGoAxxvgjAHTuDHv2wL593g6rARhjjD8CQKdO7nXLFm9HvXpQv77VAIwxvuaLANC5s3s9phnIagDGGB/zRQA45RT3ekxHsNUAjDE+5osAUL8+tGtnNQBjjAnmiwAArh/AagDGGFPINwGgc2erARhjTDDfBIBOnWD37qAf/VYDMMb4nG8CQGAkUEEzkK0KZozxOd8EgMCzAAUBID4ejhyB7OyIlckYYyLJNwGgY0f3WtAPYFNCG2N8LqwAICKDReRrEUkVkWMWfBeRGBFZ4B1fLSKJ3v4+IrLe2zaIyMigc7aKyOfesbWVdkUlqF8f2rYtVgMACwDGGN8qdVF4EYkCHgcuBNKBNSKyVFW/CEp2FbBPVTuJyFhgOjAG2AgkqWquiLQGNojIq6qa6513nqrurswLOp4iI4FsQjhjjM+FUwPoA6SqapqqHgXmA8OLpRkOzPXeLwIuEBFR1UNBN/tYQCuj0OVV5FkAawIyxvhcOAGgDbA96HO6ty9kGu+Gvx9IABCRs0VkE/A5cG1QQFDgTRFZJyKTS/pyEZksImtFZG1GRkY411SiTp0gI8O759uqYMYYn6vyTmBVXa2qXYHewB0iEusd6q+qZwEXA9eLyMASzp+tqkmqmtSiRYsKlaXIUFCrARhjfC6cALADaBf0ua23L2QaEakLxAN7ghOo6pdAFtDN+7zDe90FLMY1NVWpwFDQzZuxGoAxxvfCCQBrgM4i0kFE6gFjgaXF0iwFJnrvLwPeVVX1zqkLICLtgdOArSISJyKNvP1xwCBch3GVCgwFTU0FGjaEOnWsBmCM8a1SRwF5I3h+B6wAooA5qrpJRO4H1qrqUuBpYJ6IpAJ7cUECoD+QLCI5QD5wnaruFpFTgMUiEijDi6r6RmVfXHENGkCbNl4NQMSmgzDG+FqpAQBAVZcDy4vtmxr0PhsYHeK8ecC8EPvTgDPKWtjK0LmzTQdhjDHgoyeBA4osEB8fb01Axhjf8l0A6Nw5aCio1QCMMT7muwBQZFI4qwEYY3zMdwGgyLMAzZvD9u2QkxPRMhljTCT4LgAUmRV0xAjYtw+WFh/VaowxtZ/vAkBgKGhqKnDxxW61+NmzI10sY4ypdr4LABA0EigqCn77W3jzTUhLi3SxjDGmWvkyABR5FmDSJPdE8FNPRbRMxhhT3XwZADp1gl274MAB3CoxQ4fCnDlw9Giki2aMMdXGlwHgmAXir7nGRQTrDDbG+IgvA0CRWUEBLroITj4ZnnwyYmUyxpjq5ssAUGRWUCjsDH77bdiyJWLlMsaY6uTLABAXBz/7WVANAFxncFSUdQYbY3zDlwEAio0EAvdwwNCh8Mwz1hlsjPEF3waAIgvEBwQ6g5csiUiZjDGmOvk2AHTuDDt3ekNBAwYNgvbtrTPYGOMLvg0AgZFARfp8A53B77wTonpgjDG1i+8DQJGOYLDOYGOMb/g+ABzzQ/9nP4Nhw1xn8KFD1V4uY4ypLmEFABEZLCJfi0iqiCSHOB4jIgu846tFJNHb30dE1nvbBhEZGW6eVS0uDlq3DlEDAPj9792yYfffX93FMsaYalNqABCRKOBx4GKgCzBORLoUS3YVsE9VOwEzgOne/o1Akqr2BAYDT4pI3TDzrHLHDAUNGDDANQU98gisX1/dxTLGmGoRTg2gD5CqqmmqehSYDwwvlmY4MNd7vwi4QEREVQ+paq63PxbQMuRZ5X7+c9i0CfLzQxx8+GFISICrr4a8vOoumjHGVLlwAkAbYHvQ53RvX8g03g1/P5AAICJni8gm4HPgWu94OHninT9ZRNaKyNqMjIwwihu+X/7SLQj2xRchDjZrBrNmwdq17tUYY2qZKu8EVtXVqtoV6A3cISKxZTx/tqomqWpSixYtKrVsAwe611WrSkhw+eVwySVw992wdWulfrcxxkRaOAFgB9Au6HNbb1/INCJSF4gH9gQnUNUvgSygW5h5VrkOHdygn/ffLyGBCDzxhFsw5n/+B1RLSGiMMSeecALAGqCziHQQkXrAWKD4xPlLgYne+8uAd1VVvXPqAohIe+A0YGuYeVY5EVcLeP/949zbTz4Zpk2DN96AlJRqLZ8xxlSlUgOA12b/O2AF8CWwUFU3icj9IjLMS/Y0kCAiqcAtQGBYZ39gg4isBxYD16nq7pLyrMTrCtuAAbBjB3z77XESXX89nH023Hwz7NlznITGGHPiED2BmjWSkpJ07dq1lZrn559Djx7w7LMwcWIpCc86C8aPd4mNMeYEISLrVDWp+H7fPgkc0LUrNG16nI7ggO7d4fbbYe5cCwDGmFrB9wGgTh3o3/84HcHB7r4bLrwQrrwS/vrXKi+bMcZUJd8HAHAdwZs3w48/lpIwNhZefdUND73tNrjjDhsZZIw5YVkAwHUEQ5i1gJgYePFFuPZaeOghmDwZcnNLP88YY2oYCwC4vt0GDcIMAOCmi37iCZg6Ff75T1cjyM6u0jIaY0xlswAAREfDL34RRkdwMBG47z743/+FxYthyJBiy4sZY0zNZgHAM3Ag/Oc/kJlZxhNvvBGef95VH/r1sykjjDEnDAsAngEDXH/uhx+W4+Tx4+H11yE9Hfr0KWcmxhhTvSwAeM4+2zUFhd0PUNyvfgWffAJNmsD558O8eZVZPGOMqXQWADwNGkBSUgUCALgFBj75xDUFTZgAd95ZwmIDxhgTeRYAggwYAGvWwOHDFcikWTNYscItJPPgg3DZZfDTT5VWRmOMqSwWAIIMHAg5ObB6dQUzio6GJ5+EGTNgyRI44wxYtMgeGjPG1CgWAIL06+dGd5ZpOGhJRNzsoW+9BfXrw+jRbgmyDz6ohMyNMabiLAAEadLEzQxaoX6A4s4/3y0s//TT8N13rp1p5Ej4+utK/BJjjCk7CwDFDBgAH3/smoIqTVQUTJrkJhx64AF45x03Dek110BqaiV+kTHGhM8CQDEDB7o+288+q4LMGzSAu+5yN/1rr3XTSp96quso/uSTKvhCY4wpmQWAYso0MVx5nXQSPPaYe2r4jjvg3XfdXBQDBrhOYxs6aoypBhYAimnVCjp1Ct0RfPgw7N1biV/WurVbb/i779ycQunpMGIEdOkCzzxTye1QxhhTlAWAEAYOhJUrXbP9RRe5xcCaNXMtOM2buwlAK1XDhm5Ooc2bYf58N2po0iQXiR5/vIIPJhhjTGhhBQARGSwiX4tIqogkhzgeIyILvOOrRSTR23+hiKwTkc+91/ODzlnp5bne206qtKuqoJEj4ehRePNN2LfP3YfHjXM/1gcOhN/9DjZsqIIvrlsXxoyBTz+FZcugbVv3ZR06wCOPQFZWFXypMcavSl0UXkSigG+AC4F0YA0wTlW/CEpzHdBDVa8VkbHASFUdIyJnAjtV9XsR6QasUNU23jkrgdtUNexV3qtiUfiSqLqh/MXt2gVnnglxcbBuHTRqVMWFeO89F3neftstXjx4sOsrGDDANRXVsUqcMeb4KrIofB8gVVXTVPUoMB8YXizNcGCu934RcIGIiKp+pqrfe/s3AfVFJKZ8l1C9Qt38wfXfpqTAli1uFGeVPtwrAuee6x4m++QTuPhi1zZ13XWuXapFCxg+3NUONm2qwoIYY2qjcAJAG2B70Od0b1/INKqaC+wHEoqlGQV8qqpHgvY94zX/3CMS+pYrIpNFZK2IrM3IyAijuFVv4ED4059cIHjqqWr60rPPhhdegB073DDSZ55xN/8vvoApU6BbN/dswX33wZdfVlOhjDEnsmppPxCRrsB04Jqg3eNVtTswwNv+O9S5qjpbVZNUNalFixZVX9gwJSfDoEGu77ZK+gNKIgIdO8JvfgNz5riO4/R0N6y0eXMXALp0cTWE++93NQObg8gYE0I4AWAH0C7oc1tvX8g0IlIXiAf2eJ/bAouBCaq6JXCCqu7wXg8CL+Kamk4Ydeq4Kf8TEtySwAcPRrAwbdrA9de7/oL0dJg1y/UX3Huvqxl06OCajZYtg0OHIlhQY0xNEk4AWAN0FpEOIlIPGAssLZZmKTDRe38Z8K6qqog0AZYByapasEyWiNQVkebe+2hgKLCxQlcSAYH+gNTUaugPCNfPfgY33OAeZNi+3c1KesYZMHcuDB3qItaQIfDoo65vYceOGlJwY0x1K3UUEICIDAFmAlHAHFWdJiL3A2tVdamIxALzgDOBvcBYVU0TkbuBO4DNQdkNAn4CVgHRXp5vA7eoat7xylGdo4DKYto0uPtuuOkm1zdQpSODyuvIERcUli2D5ctd01FA48au2ej0010/Qt++0KsXxMZGrrzGmEpT0iigsAJATVFTA0B+vmthefJJ9yTx9OlwxRU1fITmzp2us/iLL4puO3e64/XquSDwy18Wbq1aRbbMxphysQBQDVavdp3C//63G7Qza5ZbI/6EsmuXmw71o4/c4vZr17raA7gn4vr3L9xOPbXk8bLGmBrDAkA1yc93ncPJyfDjj26wzvTprr/ghHTkiJsa9cMP3WI2H3wAu3e7Yy1auEDQowckJrrO5sRE1yldt24kS22MCWIBoJodPOim/p8xwz05/MknteTHsip8842bLjUQENLSinYkR0VBu3YuIHToAKec4rbA+xYtasl/DGNODBYAIuSpp2DyZLdO/KBBkS5NFTlyxI042rq1cPv228Ltxx+Lpo+Lc88ydOrktsD7jh3d/EdRURG4CGNqLwsAEXLkSOH9beXKSJcmQn76qTAopKW5eTQCW1qam3kvoG7dwtpDcLNS4H3r1jW8d92YmqekAGANtVUsJgZuuw1+/3vXjN6vX6RLFAFxcW54adeuxx7Ly3MPr23Z4h6oCK5FLF9+bO2hXj1o374wMLRr54JC69ZulFLr1q7DxWoRxpTKagDV4Kef3L2qTx83DN+UweHDsG1b0aal4CamQId0sDp1oGVL91BcSVvr1q4vwmoTxgesBhBBcXFw883uYbHPPnOdwiZM9evDaae5LZQjR1wt4Ycfim7ff+9ev/vO9cCHmkiwbt3CWkOgBtGyZeFrYGvWDOLjbWSTqXWsBlBNMjNdy8VFF8HChZEujQ8dPeoCxY4dRYNEIFB8/717CC4jo+SpMeLioEkTFwyaNHE1iHbtXMd1u3aF79u0cU1VxtQQVgOIsCZN3HxtDz0EX31V8g9aU0Xq1YOTT3bb8eTmumalnTvd9uOPblm4/fvdlplZ+JqW5ibgy8wsmkedOi4QFB/+2r69myckLs6tLxoX5zbrrzARYjWAarRrl+sLGDPGTecfyo8/uqUox42D6OjS8/zhBzfH26mnuhmhE4qvwmCqXlaWGwabnl44HDbQR5GW5v4nHU9MTGGtomlT9xp436qVCxyB4NWunUtvTBnYMNAa4qab4Ikn3ICX9u2LHlu4EP7nf2DvXrcucUrK8f+tZ2S4BcO2boWcHLccwNNPu4XDTA1y6JD7n7R9uwsWhw65kQE//eTeZ2UV1ioyM12NI/C6e/exTVKtWrmtcePCLT7evTZtWhgsTj7Z9W1Y34XvWQCoIdLTXWvA5MnuFzvAnj1u7ff586F3b7fs75/+5G7kL7/s+kGL27cPzj/fNSe9/rr7wXjFFW79l2uvhYcfhoYNq/XSTFU4csT1W2zb5jq0v/vOvd+1Cw4cKNwCTVQ5OUXPj4pyfRJt27rmpwYNjt3q1XPp6tYturVo4R5i6djRdYSbE5YFgBrk6qvdfEFbt7q51q6+2gWBP/4Rbr/d/dv75z9dkDj3XFi6tOjN/OBBuPBC+PRTd2zwYLc/O9uNNHr0URdk5s2DX/wiEldoIubgQVfTCA4W333ngkigxlF8y80tPd8mTdwfVceObhhtTEzhVq+ee42LczWONm3clpBgU37UEBYAapDUVPj5z92/pc2b3Vxqc+dCz55F073wAkyc6GYWXb7c1fIPHXLruXzwASxaBCNGHJv/e++587Zvd4uC3X23/Ts0x6HqHsjLzS18zclxHVLBT20Htp073aiqwCyxJalXr/C5i+bNXS2i+BYX59adKL4lJLigY3+4lcICQA1zxRWujT85GaZOLbmt/+WXYexYt6jX0qVw5ZVuIa8XX3T7S3LggOtPePFFN0X1jBn2zJOpZKouUBw54rasLNfhvWOH277/vvB171637dkT/rKkjRq5foz27Qs7wlu1cgEiJqbwNfC+YcPCkVUNG4Y3isInLADUMIcPux9SiYmlp122DEaNcj+GsrPdWvBXXln6eapw663u5n/llW5iOhtxaCIuO9t1Yu3d64JBdnbR7fBhN8IhuAlr2zaXviyio10gaN266PMagddWrVw/R/PmtT5Y2HMANUz9+uHd/AEuuQReew0mTIB77gnv5g8uYPz1r25wyH33uR9ozz9fec8o5eS4/Hv1cn0SxoQlNrbw6euyyMpygeHIERcogl8PHy4cWZWVVfj+wAFXK9m+HTZscL+6Qv3obdrUBYMWLdz7Bg3cP9LgzvKGDV2waN7cNVEF3jdtesJWr8MKACIyGPhf3Pq9/1TVh4odjwGeA3oBe4AxqrpVRC4EHgLqAUeBKar6rndOL+BZoD6wHLhJT6TqSDX71a9cbbqsTaIirh+gUSM3Kd2hQ/DSS6FHFpXFzp1w+eVumeEWLVy/RuPGFcvTmONq2LDiQ9uOHnVNUtu3u5FUu3a5oBL8umOH+4dy+HDRzvKSiBQ+t9GsWdHXuLjCQBIcUBo3dmkSEgrTRuDp8VIDgIhEAY8DFwLpwBoRWaqqXwQluwrYp6qdRGQsMB0YA+wGLlXV70WkG7ACaOOd83fgamA1LgAMBl6vnMuqnSrSH3brrS4IXHutq1EsWVL+xevXrIH/+i/XnHvPPW7I6kMPwZ//XP7yGVMt6tUrnF68LFRdzWLPHrft3u22wPtAk1bgNdBkVVrwCBaoYRSfjyrw/tJLKz1IhFMD6AOkqmoagIjMB4YDwQFgOHCv934R8JiIiKp+FpRmE1Dfqy00Axqr6idens8BI7AAUKUmT3Y/SCZOdDMzN29+7OCPevXcsNJx4yAp6digM2cOXHed+5v88EM3sV1amutnuPba0mdaMOaEJOJ+MTVqVL7gEWimCtQs9u8v7BQPdJDv3etqIDt3un9UH39cdG6qw4cr/bLCCQBtgO1Bn9OBs0tKo6q5IrIfSMDVAAJGAZ+q6hERaePlE5xnG0IQkcnAZICT7e5SYePHu9rm3//u/qajogqfAYqKcj9gHnvM3dA7dXIjjcaNc+9vvtmd96tfuRFMzZu7PP/8Zzda6a673LMHxpggIoXDW5s2Ldu5gbmpdu1y51eyaukEFpGuuGahMi+KqKqzgdngRgFVctF8acgQt5Vk3z545RV3k//zn93axs2auR8of/gDTJtWdHaBk092C948+KCb6iLpmLEGxphyCUxZ3qpVlWQfTtf1DqBd0Oe23r6QaUSkLhCP6wxGRNoCi4EJqrolKH3bUvI0EdK0KVx1Fbz9tusPmzULBgxwcxVNnx56apnkZLcQ1623ljybcmX797/dVBjGmPIJJwCsATqLSAcRqQeMBZYWS7MUmOi9vwx4V1VVRJoAy4BkVf0wkFhVfwAOiEhfERFgArCkYpdiqkKrVnDDDfB//wejR5ecLjDUdNUq18Fc1T76yAWl/v3dlBrGmLIL60EwERkCzMQNA52jqtNE5H5graouFZFYYB5wJrAXGKuqaSJyN3AHsDkou0GquktEkigcBvo6cENpw0Br04NgtVFurpvWIjcXNm6sulFt27a5SfMaNXLNUu3bu4DQoEHVfF9FZGe7WsoXX7iyBvpgjKlO9iSwqRbLlrn1CWbNcjWHynbwIPTr5x4OXb3aDZa45BK3xsKLL0Z+6pi0NDcl96ZNbktLg/z8wuPNm7s+lKuusqeyTfUpKQCcmI+vmRpryBC44ALXHFR8oay8PPcMzo8/li/vvDz49a/dr+mXXnIT6l18seuonj8fHnmkwsU/Rll+H23bBgMHwl/+At984yb3u/tuWLAAPv/cPT9x+ulwzTWuBvPBB5VfXmPKRFVPmK1Xr15qar7161VFVM85R3XkSNU+fVTbtFGNilIF1Tp1VG+/XfXw4bLle9tt7vzHHy+6Pz9fdfRol+8bb1TaZeiqVart2qlOmKCanX38tLt2qZ56qmp8vOqGDSWny89XnT9ftW1bdy3jxqlu3155ZTYmFFxz/TH31Ijf1MuyWQA4cdx0k7sZnn666q9+pTpxouqdd7qb96RJ7i/vtNNUP/44vPyeftqdc/31oY9nZal2767apInq5s3HHs/OVn3zTdUnn1Tdv//435WfrzpzpmrduqqtW7vvHTBAdffu0OkPHFDt1Us1Nlb1/ffDu56sLNV77lGNiVFt0ED12mtV16xx321MZbMAYGqUFSvcr+s6ddwv+0OHSk773nuq0dGqF16ompNTcrotW1SbNlXt2lX14EHVtDQXcIYOdTdZ16Cj2ry5u8GH+lWflaX661+7dMOHq2ZmqqakuBt1p06qX39dNH12tur557vazWuvlf2/w7ffuuBYv777zu7dXdkyMoqmy8lR3bhR9YUXVP/wB9XZsy1YmPBZADA1zv79qtdc4/4KTz1V9e23VT/6SPWZZ1STk13zUZcu7ub/85+r7ttXep5vvumCStOmhTf8U05xNYfXXlP98EPVCy5w+xMTVZ9/XjUvz52bmupuwCKqDzxQuF/Vnde8uWqzZi4gqarm5qqOGuXyeu65iv23yMxU/cc/VHv3dvnVq6d62WWqV16petZZLgAFrifQlPbf/11601R57d9f9ia6srIAVn0sAJga6623VNu3L7zBgbvpn3666ogRLhh89134+c2erXrJJe6X9NdfH3ujyc93NZCePd139eyp+te/uuajZs1K7kdITXWBKDra3fAnT3bnP/pouS89pP/8R/Xmm13AadHCNaHdeqvqvHnu2JEjqn/6k/vuX/5SdefOyvvuNWtUr7jCXeNJJ6n+7W/u+yrb+++7/+cPPFD+PHJyXDC+9VZXW1u1qrJKV/tYADA12oED7pf/q6+qfvPN8Zt6KktenmtSSUwsDARpacc/Z+9e1XPPLQxUd9xRdeXLzz/+r+SFC13TUfv2LjCU19GjqgsWuGACqg0buhpT4DoTE13Ay80t/3cE++c/XYCJjXX5v/xy+OdmZrqyjh9fWMuLjnbBElzzXXp65ZSzIlaudE2GTz4Z6ZI4FgCMKUF2tuqyZcfvhwh25Ij7hZ6cHPlmjDVrXEd1w4Zl74P45hv3CzwwIumUU1ytKdBJHqgpnXWWO96tm+qSJeW/5pwc1RtvdHkNGqT6ww9uhFhcnOvfOJ68PNUpU9zNHlQTEtzorJdecuX96afCTvW4ONXp06um5hKOF15wTXgxMa45cd68yJQjmAUAY2qp9HR3k65TR3XqVNcs8v33oZu+1q1Tvftu11EeqMWcf767sZf0Cz8vz9U2Tj3Vpe/TR3XRorLVCPbscU1ZoHrLLYU1vPR01ZYt3a/lvXtDn3vkiBsuC+6m//77JX/3li2qw4ZpQb/S669XX5DOz1d98EH33QMHuv8H553n+myWLKmeMpTEAoAxtVhWVmGHdGBr2NA1a40e7forAv0sdeq4ZzRmzlTdujX878jJUX3qKdWOHV0+HTu6UVY//XT88zZtcmnr1VOdM+fY4x984H7ZDx587I39wAE3+gvczTXcm/nrr6t27uzO69TJ1R4++qhox35lyskp7BMaN66wc/7AARcwY2LcIIdIKSkA2FQQxtQSqm5ivG++gc2bC7dvvnFrjJxzDowcCcOGuWU8yysvz00O+PDDbjqOhAS4/nq44gq3fsmWLW6J0C1b3LZhg5ss8JVX4Je/DJ3n7NnuCenkZDetOLgp8C+5BD77DJ56Kvy1sAOOHoXnnoNFi+Ddd90a1q1bw/DhMGKEW6FxyxY3XUegrGlp7txOndzWuXPha4cOblr04sv/HjzopiJ5/XW44w43fXpwmr173X/7b7+Fd96Bs4uvpoKbL+q55wqXbq3sNeptLiBjTKVSdavCPfwwLC02P7AItGsHHTvCaae5G2O7dqHzCbjmGhcIFixwU2UMGuSmI1+40M0vVRGZmW6eqsWL3Y06eJXGqCi3pkXHjnDKKW5faqoLntu3F82nbl0XPE86qXDFxvXr3fQkTzzhVt0L5Ycf3Oy1e/fCypVu0sTMTHetzz4Ln3ziypGX52a4XbjQBavKYgHAGFNlvv7a3dgCN/3ERIiJKVseR47A+ee7G2rjxu4X/GuvwS9+UbllPXzYlTUqypX15JNL/sV9+LCrFWze7OZ62rmzcNXGwGt+PvzjH8dfZAlc7ax/fzdb7nnnuVpUdrZbnvXKK10N6t134be/ddf/0ksufWWwAGCMqfF++MGtKBcVBStWuMnzapOvvnITBubmuokNr7wSzjqr6Cy2n38O//VfLmD89a9uVt2KznJbUgColiUhjTEmHK1buxtgdLRrD69tTjvNNS/FxJRcQ+reHdauhYkT3RKrq1e7prG4uMovj00HbYypUZo1q503/4DGjUtvHouPd53mganO+/Z1U6lXNgsAxhhTA9Wp4zrP33jDjUKqyMitklgTkDHG1GAXXui2qmA1AGOM8amwAoCIDBaRr0UkVUSSQxyPEZEF3vHVIpLo7U8QkX+JSJaIPFbsnJVenuu97aRKuSJjjDFhKbUJSESigMeBC4F0YI2ILFXVL4KSXQXsU9VOIjIWmA6MAbKBe4Bu3lbceFW1cZ3GGBMB4dQA+gCpqpqmqkeB+cDwYmmGA3O994uAC0REVPUnVf0AFwiMMcbUIOEEgDZA8APR6d6+kGlUNRfYDySEkfczXvPPPSKhH3UQkckislZE1mZkZISRpTHGmHBEshN4vKp2BwZ423+HSqSqs1U1SVWTWlTFOChjjPGpcALADiB4Gqe23r6QaUSkLhAP7Dlepqq6w3s9CLyIa2oyxhhTTcIJAGuAziLSQUTqAWOBYnP/sRSY6L2/DHhXjzPJkIjUFZHm3vtoYCiwsayFN8YYU35hTQYnIkOAmUAUMEdVp4nI/bhFBpaKSCwwDzgT2AuMVdU079ytQGOgHpAJDAK2AauAaC/Pt4FbVDWvlHJkeOeWR3NgdznPPZHZdfuLXbe/hHvd7VX1mDb0E2o20IoQkbWhZsOr7ey6/cWu218qet32JLAxxviUBQBjjPEpPwWA2ZEuQITYdfuLXbe/VOi6fdMHYIwxpig/1QCMMcYEsQBgjDE+VesDQGlTWdcmIjJHRHaJyMagfc1E5C0R2ey9No1kGauCiLTzph3/QkQ2ichN3v5afe0iEisi/xaRDd513+ft7+BNy57qTdNeL9JlrQoiEiUin4nIa97nWn/dIrJVRD735lBb6+0r9995rQ4AQVNZXwx0AcaJSJfIlqpKPQsMLrYvGXhHVTsD73ifa5tc4FZV7QL0Ba73/j/X9ms/ApyvqmcAPYHBItIXNx37DFXtBOzDTddeG90EfBn02S/XfZ6q9gwa/1/uv/NaHQAIbyrrWkNVV+GexA4WPFX3XGBEdZapOqjqD6r6qff+IO6m0IZafu3qZHkfo71NgfNx07JDLbxuABFpC1wC/NP7LPjguktQ7r/z2h4AwpnKurZrqao/eO9/BFpGsjBVzVuN7kxgNT64dq8ZZD2wC3gL2AJketOyQ+39m58J/AHI9z4n4I/rVuBNEVknIpO9feX+O7dF4X1EVVVEau24XxFpCLwM3KyqB4KXmKit1+7Nn9VTRJoAi4HTIluiqiciQ4FdqrpORM6NcHGqW39V3eEtofuWiHwVfLCsf+e1vQYQzlTWtd1OEWkN4L3uinB5qoQ3q+zLwAuq+oq32xfXDqCqmcC/gF8ATbxp2aF2/s33A4Z5E03OxzX9/C+1/7qDp9HfhQv4fajA33ltDwDhTGVd2wVP1T0RWBLBslQJr/33aeBLVX006FCtvnYRaeH98kdE6uPW7f4SFwgu85LVuutW1TtUta2qJuL+Tb+rquOp5dctInEi0ijwHjez8kYq8Hde658EDjWVdWRLVHVEJAU4FzdF7E7gj8D/AQuBk3FTaV+uqsU7ik9oItIfeB/4nMI24Ttx/QC19tpFpAeu0y8K92NuoareLyKn4H4ZNwM+A65Q1SORK2nV8ZqAblPVobX9ur3rW+x9rAu86E3Nn0A5/85rfQAwxhgTWm1vAjLGGFMCCwDGGONTFgCMMcanLAAYY4xPWQAwxhifsgBgjDE+ZQHAGGN86v8BQvptwyW5ERcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training\n",
      "saved the model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MT = ModelTrainer(data_dir)\n",
    "MT.train_full_model()\n",
    "print(\"finished training\")\n",
    "torch.save(MT.strongest_model, model_path + \"full_model\")\n",
    "model = torch.load(model_path + \"full_model\")\n",
    "model.eval()\n",
    "print(\"saved the model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "european-things",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test loss MAE(L1): ', 0.0]\n",
      "['test loss MSE: ', 0.0]\n",
      "['test loss MAE(L1) timestep 1: ', 0.02047521910437989]\n",
      "['test loss MSE timestep 1: ', 0.0015837723040252939]\n",
      "['test loss MAE(L1) timestep 5: ', 0.02229656567501407]\n",
      "['test loss MSE timestep 5: ', 0.0018254274090900757]\n",
      "['test loss MAE(L1) timestep 10: ', 0.018959840466194446]\n",
      "['test loss MSE timestep 10: ', 0.0017116586486187611]\n",
      "['sheer x test loss MAE(L1): ', 0.02047521910437989]\n",
      "['sheer x test loss MSE: ', 0.0015837723040252939]\n",
      "['sheer y test loss MAE(L1): ', 0.02229656567501407]\n",
      "['sheer y test loss MSE: ', 0.0018254274090900757]\n",
      "['z test loss MAE(L1): ', 0.018959840466194446]\n",
      "['z test loss MSE: ', 0.0017116586486187611]\n",
      "['sheer x test loss MAE(L1) timestep 1: ', 0.014294787641200754]\n",
      "['sheer x test loss MSE timestep 1: ', 0.000647175583077432]\n",
      "['sheer y test loss MAE(L1) timestep 1: ', 0.014787987584898632]\n",
      "['sheer y test loss MSE timestep 1: ', 0.0006762196027488071]\n",
      "['z test loss MAE(L1) timestep 1: ', 0.013990507787832665]\n",
      "['z test loss MSE timestep 1: ', 0.0007711782640225941]\n",
      "['sheer x test loss MAE(L1) timestep 5: ', 0.019872972713635556]\n",
      "['sheer x test loss MSE timestep 5: ', 0.0014381832697951708]\n",
      "['sheer y test loss MAE(L1) timestep 5: ', 0.021591425784641786]\n",
      "['sheer y test loss MSE timestep 5: ', 0.0016393769907327147]\n",
      "['z test loss MAE(L1) timestep 5: ', 0.018257952212459513]\n",
      "['z test loss MSE timestep 5: ', 0.0015518331919526054]\n",
      "['sheer x test loss MAE(L1) timestep 10: ', 0.026521067222255088]\n",
      "['sheer x test loss MSE timestep 10: ', 0.002570015263913702]\n",
      "['sheer y test loss MAE(L1) timestep 10: ', 0.029528492462215207]\n",
      "['sheer y test loss MSE timestep 10: ', 0.003064573665404977]\n",
      "['z test loss MAE(L1) timestep 10: ', 0.024147349196146167]\n",
      "['z test loss MSE timestep 10: ', 0.002742692956633705]\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(model_path + \"full_model\")\n",
    "model.eval()\n",
    "# test model on the full test sample:\n",
    "# model = MT.strongest_model\n",
    "data_dir = MT.data_dir\n",
    "\n",
    "criterion1 = nn.L1Loss()\n",
    "criterion2 = nn.MSELoss()\n",
    "\n",
    "test_lossesMAE_x = 0.0\n",
    "test_lossesMSE_x = 0.0\n",
    "test_lossesMAE_y = 0.0\n",
    "test_lossesMSE_y = 0.0\n",
    "test_lossesMAE_z = 0.0\n",
    "test_lossesMSE_z = 0.0\n",
    "\n",
    "test_lossesMAE_t1 = 0.0\n",
    "test_lossesMSE_t1 = 0.0\n",
    "test_lossesMAE_t5 = 0.0\n",
    "test_lossesMSE_t5 = 0.0\n",
    "test_lossesMAE_t10 = 0.0\n",
    "test_lossesMSE_t10 = 0.0\n",
    "\n",
    "test_lossesMAE_x_ts1 = 0.0\n",
    "test_lossesMSE_x_ts1 = 0.0\n",
    "test_lossesMAE_y_ts1 = 0.0\n",
    "test_lossesMSE_y_ts1 = 0.0\n",
    "test_lossesMAE_z_ts1 = 0.0\n",
    "test_lossesMSE_z_ts1 = 0.0\n",
    "\n",
    "test_lossesMAE_x_ts5 = 0.0\n",
    "test_lossesMSE_x_ts5 = 0.0\n",
    "test_lossesMAE_y_ts5 = 0.0\n",
    "test_lossesMSE_y_ts5 = 0.0\n",
    "test_lossesMAE_z_ts5 = 0.0\n",
    "test_lossesMSE_z_ts5 = 0.0\n",
    "\n",
    "test_lossesMAE_x_ts10 = 0.0\n",
    "test_lossesMSE_x_ts10 = 0.0\n",
    "test_lossesMAE_y_ts10 = 0.0\n",
    "test_lossesMSE_y_ts10 = 0.0\n",
    "test_lossesMAE_z_ts10 = 0.0\n",
    "test_lossesMSE_z_ts10 = 0.0\n",
    "\n",
    "tactile_predictions = []\n",
    "tactile_groundtruth = []\n",
    "experiment_time_steps = []\n",
    "test_lossesMAE = 0.0\n",
    "test_lossesMSE = 0.0\n",
    "with torch.no_grad():\n",
    "    for index__, batch_features in enumerate(MT.test_full_loader):\n",
    "        # 2. Reshape data and send to device:\n",
    "        action = batch_features[0].permute(1,0,2).to(device)\n",
    "        tactile1 = batch_features[1].permute(1,0,2).to(device)\n",
    "        tactile2 = batch_features[1].permute(1,0,2).to(device)\n",
    "        tactile  = torch.dstack((tactile1,tactile2))\n",
    "        tp = model.forward(tactiles=tactile, actions=action)\n",
    "        experiment_time_steps.append([batch_features[3], batch_features[4]])\n",
    "        tactile_predictions.append(tp)  # Step 3. Run our forward pass.\n",
    "        tactile_groundtruth.append(tactile[context_frames:])\n",
    "        # calculate losses for specific timesteps\n",
    "        test_lossMAE_t1 = criterion1(tp[0,:,:].to(device), tactile[context_frames:][0,:,:])\n",
    "        test_lossesMAE_t1 += test_lossMAE_t1.item() \n",
    "        test_lossMSE_t1 = criterion2(tp[0,:,:].to(device), tactile[context_frames:][0,:,:])\n",
    "        test_lossesMSE_t1 += test_lossMSE_t1.item() \n",
    "        test_lossMAE_t5 = criterion1(tp[4,:,:].to(device), tactile[context_frames:][4,:,:])\n",
    "        test_lossesMAE_t5 += test_lossMAE_t5.item() \n",
    "        test_lossMSE_t5 = criterion2(tp[4,:,:].to(device), tactile[context_frames:][4,:,:])\n",
    "        test_lossesMSE_t5 += test_lossMSE_t5.item() \n",
    "        test_lossMAE_t10 = criterion1(tp[9,:,:].to(device), tactile[context_frames:][9,:,:])\n",
    "        test_lossesMAE_t10 += test_lossMAE_t10.item() \n",
    "        test_lossMSE_t10 = criterion2(tp[9,:,:].to(device), tactile[context_frames:][9,:,:])\n",
    "        test_lossesMSE_t10 += test_lossMSE_t10.item() \n",
    "        \n",
    "        # calculate losses for specific forces\n",
    "        test_lossMAE_x = criterion1(tp[:,:,:16].to(device), tactile[context_frames:][:,:,:16])\n",
    "        test_lossesMAE_x += test_lossMAE_x.item() \n",
    "        test_lossMSE_x = criterion2(tp[:,:,:16].to(device), tactile[context_frames:][:,:,:16])\n",
    "        test_lossesMSE_x += test_lossMSE_x.item() \n",
    "        test_lossMAE_y = criterion1(tp[:,:,17:32].to(device), tactile[context_frames:][:,:,17:32])\n",
    "        test_lossesMAE_y += test_lossMAE_y.item() \n",
    "        test_lossMSE_y = criterion2(tp[:,:,17:32].to(device), tactile[context_frames:][:,:,17:32])\n",
    "        test_lossesMSE_y += test_lossMSE_y.item() \n",
    "        test_lossMAE_z = criterion1(tp[:,:,33:48].to(device), tactile[context_frames:][:,:,33:48])\n",
    "        test_lossesMAE_z += test_lossMAE_z.item() \n",
    "        test_lossMSE_z = criterion2(tp[:,:,33:48].to(device), tactile[context_frames:][:,:,33:48])\n",
    "        test_lossesMSE_z += test_lossMSE_z.item() \n",
    "\n",
    "        # calculate losses for specific timesteps and forces \n",
    "        test_lossMAE_x_ts1 = criterion1(tp[0,:,:16].to(device), tactile[context_frames:][0,:,:16])\n",
    "        test_lossesMAE_x_ts1 += test_lossMAE_x_ts1.item() \n",
    "        test_lossMSE_x_ts1 = criterion2(tp[0,:,:16].to(device), tactile[context_frames:][0,:,:16])\n",
    "        test_lossesMSE_x_ts1 += test_lossMSE_x_ts1.item() \n",
    "        test_lossMAE_y_ts1 = criterion1(tp[0,:,17:32].to(device), tactile[context_frames:][0,:,17:32])\n",
    "        test_lossesMAE_y_ts1 += test_lossMAE_y_ts1.item() \n",
    "        test_lossMSE_y_ts1 = criterion2(tp[0,:,17:32].to(device), tactile[context_frames:][0,:,17:32])\n",
    "        test_lossesMSE_y_ts1 += test_lossMSE_y_ts1.item() \n",
    "        test_lossMAE_z_ts1 = criterion1(tp[0,:,33:48].to(device), tactile[context_frames:][0,:,33:48])\n",
    "        test_lossesMAE_z_ts1 += test_lossMAE_z_ts1.item() \n",
    "        test_lossMSE_z_ts1 = criterion2(tp[0,:,33:48].to(device), tactile[context_frames:][0,:,33:48])\n",
    "        test_lossesMSE_z_ts1 += test_lossMSE_z_ts1.item() \n",
    " \n",
    "        test_lossMAE_x_ts5 = criterion1(tp[4,:,:16].to(device), tactile[context_frames:][4,:,:16])\n",
    "        test_lossesMAE_x_ts5 += test_lossMAE_x_ts5.item() \n",
    "        test_lossMSE_x_ts5 = criterion2(tp[4,:,:16].to(device), tactile[context_frames:][4,:,:16])\n",
    "        test_lossesMSE_x_ts5 += test_lossMSE_x_ts5.item() \n",
    "        test_lossMAE_y_ts5 = criterion1(tp[4,:,17:32].to(device), tactile[context_frames:][4,:,17:32])\n",
    "        test_lossesMAE_y_ts5 += test_lossMAE_y_ts5.item() \n",
    "        test_lossMSE_y_ts5 = criterion2(tp[4,:,17:32].to(device), tactile[context_frames:][4,:,17:32])\n",
    "        test_lossesMSE_y_ts5 += test_lossMSE_y_ts5.item() \n",
    "        test_lossMAE_z_ts5 = criterion1(tp[4,:,33:48].to(device), tactile[context_frames:][4,:,33:48])\n",
    "        test_lossesMAE_z_ts5 += test_lossMAE_z_ts5.item() \n",
    "        test_lossMSE_z_ts5 = criterion2(tp[4,:,33:48].to(device), tactile[context_frames:][4,:,33:48])\n",
    "        test_lossesMSE_z_ts5 += test_lossMSE_z_ts5.item() \n",
    "\n",
    "        test_lossMAE_x_ts10 = criterion1(tp[9,:,:16].to(device), tactile[context_frames:][9,:,:16])\n",
    "        test_lossesMAE_x_ts10 += test_lossMAE_x_ts10.item() \n",
    "        test_lossMSE_x_ts10 = criterion2(tp[9,:,:16].to(device), tactile[context_frames:][9,:,:16])\n",
    "        test_lossesMSE_x_ts10 += test_lossMSE_x_ts10.item() \n",
    "        test_lossMAE_y_ts10 = criterion1(tp[9,:,17:32].to(device), tactile[context_frames:][9,:,17:32])\n",
    "        test_lossesMAE_y_ts10 += test_lossMAE_y_ts10.item() \n",
    "        test_lossMSE_y_ts10 = criterion2(tp[9,:,17:32].to(device), tactile[context_frames:][9,:,17:32])\n",
    "        test_lossesMSE_y_ts10 += test_lossMSE_y_ts10.item() \n",
    "        test_lossMAE_z_ts10 = criterion1(tp[9,:,33:48].to(device), tactile[context_frames:][9,:,33:48])\n",
    "        test_lossesMAE_z_ts10 += test_lossMAE_z_ts10.item() \n",
    "        test_lossMSE_z_ts10 = criterion2(tp[9,:,33:48].to(device), tactile[context_frames:][9,:,33:48])\n",
    "        test_lossesMSE_z_ts10 += test_lossMSE_z_ts10.item()\n",
    "\n",
    "performance_data = []\n",
    "performance_data.append([\"test loss MAE(L1): \", (test_lossesMAE / index__)])\n",
    "performance_data.append([\"test loss MSE: \", (test_lossesMSE / index__)])\n",
    "performance_data.append([\"test loss MAE(L1) timestep 1: \", (test_lossesMAE_x / index__)])\n",
    "performance_data.append([\"test loss MSE timestep 1: \", (test_lossesMSE_x / index__)])\n",
    "performance_data.append([\"test loss MAE(L1) timestep 5: \", (test_lossesMAE_y / index__)])\n",
    "performance_data.append([\"test loss MSE timestep 5: \", (test_lossesMSE_y / index__)])\n",
    "performance_data.append([\"test loss MAE(L1) timestep 10: \", (test_lossesMAE_z / index__)])\n",
    "performance_data.append([\"test loss MSE timestep 10: \", (test_lossesMSE_z / index__)])\n",
    "performance_data.append([\"sheer x test loss MAE(L1): \", (test_lossesMAE_x / index__)])\n",
    "performance_data.append([\"sheer x test loss MSE: \", (test_lossesMSE_x / index__)])\n",
    "performance_data.append([\"sheer y test loss MAE(L1): \", (test_lossesMAE_y / index__)])\n",
    "performance_data.append([\"sheer y test loss MSE: \", (test_lossesMSE_y / index__)])\n",
    "performance_data.append([\"z test loss MAE(L1): \", (test_lossesMAE_z / index__)])\n",
    "performance_data.append([\"z test loss MSE: \", (test_lossesMSE_z / index__)])\n",
    "performance_data.append([\"sheer x test loss MAE(L1) timestep 1: \", (test_lossesMAE_x_ts1 / index__)])\n",
    "performance_data.append([\"sheer x test loss MSE timestep 1: \", (test_lossesMSE_x_ts1 / index__)])\n",
    "performance_data.append([\"sheer y test loss MAE(L1) timestep 1: \", (test_lossesMAE_y_ts1 / index__)])\n",
    "performance_data.append([\"sheer y test loss MSE timestep 1: \", (test_lossesMSE_y_ts1 / index__)])\n",
    "performance_data.append([\"z test loss MAE(L1) timestep 1: \", (test_lossesMAE_z_ts1 / index__)])\n",
    "performance_data.append([\"z test loss MSE timestep 1: \", (test_lossesMSE_z_ts1 / index__)])\n",
    "performance_data.append([\"sheer x test loss MAE(L1) timestep 5: \", (test_lossesMAE_x_ts5 / index__)])\n",
    "performance_data.append([\"sheer x test loss MSE timestep 5: \", (test_lossesMSE_x_ts5 / index__)])\n",
    "performance_data.append([\"sheer y test loss MAE(L1) timestep 5: \", (test_lossesMAE_y_ts5 / index__)])\n",
    "performance_data.append([\"sheer y test loss MSE timestep 5: \", (test_lossesMSE_y_ts5 / index__)])\n",
    "performance_data.append([\"z test loss MAE(L1) timestep 5: \", (test_lossesMAE_z_ts5 / index__)])\n",
    "performance_data.append([\"z test loss MSE timestep 5: \", (test_lossesMSE_z_ts5 / index__)])\n",
    "performance_data.append([\"sheer x test loss MAE(L1) timestep 10: \", (test_lossesMAE_x_ts10 / index__)])\n",
    "performance_data.append([\"sheer x test loss MSE timestep 10: \", (test_lossesMSE_x_ts10 / index__)])\n",
    "performance_data.append([\"sheer y test loss MAE(L1) timestep 10: \", (test_lossesMAE_y_ts10 / index__)])\n",
    "performance_data.append([\"sheer y test loss MSE timestep 10: \", (test_lossesMSE_y_ts10 / index__)])\n",
    "performance_data.append([\"z test loss MAE(L1) timestep 10: \", (test_lossesMAE_z_ts10 / index__)])\n",
    "performance_data.append([\"z test loss MSE timestep 10: \", (test_lossesMSE_z_ts10 / index__)])\n",
    "[print(i) for i in performance_data]\n",
    "\n",
    "np.save(model_path + 'performance_data', np.asarray(performance_data))\n",
    "\n",
    "# calculate tactile values for full sample:\n",
    "time_step_to_test_t1 = 0    # [batch_set, prediction frames(t1->tx)(6), batch_size, features(48)]\n",
    "time_step_to_test_t9 = 5\n",
    "predicted_data_t1 = []\n",
    "predicted_data_t9 = []\n",
    "groundtruth_data = []\n",
    "for index, batch_set in enumerate(tactile_predictions):\n",
    "    for batch in range(0, len(batch_set[0])):\n",
    "        prediction_values = batch_set[time_step_to_test_t1][batch]\n",
    "        predicted_data_t1.append(prediction_values)\n",
    "        prediction_values = batch_set[time_step_to_test_t9][batch]\n",
    "        predicted_data_t9.append(prediction_values)\n",
    "        gt_values = tactile_groundtruth[index][time_step_to_test_t1][batch]\n",
    "        groundtruth_data.append(gt_values)  \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-front",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate tactile values for full sample:\n",
    "time_step_to_test_t1 = 0    # [batch_set, prediction frames(t1->tx)(6), batch_size, features(48)]\n",
    "time_step_to_test_t5 = 4\n",
    "time_step_to_test_t9 = 9\n",
    "predicted_data_t1 = []\n",
    "predicted_data_t5 = []\n",
    "predicted_data_t9 = []\n",
    "groundtruth_data = []\n",
    "experiment_to_test = 106\n",
    "for index, batch_set in enumerate(tactile_predictions):\n",
    "    for batch in range(0, len(batch_set[0])):\n",
    "        experiment = experiment_time_steps[index][0][batch]\n",
    "        if experiment == experiment_to_test:\n",
    "            prediction_values = batch_set[time_step_to_test_t1][batch]\n",
    "            predicted_data_t1.append(prediction_values)\n",
    "            prediction_values = batch_set[time_step_to_test_t5][batch]\n",
    "            predicted_data_t5.append(prediction_values)\n",
    "            prediction_values = batch_set[time_step_to_test_t9][batch]\n",
    "            predicted_data_t9.append(prediction_values)\n",
    "            gt_values = tactile_groundtruth[index][time_step_to_test_t1][batch]\n",
    "            groundtruth_data.append(gt_values)\n",
    "\n",
    "# print(tactile_predictions[0])\n",
    "# plt.plot([i for i in range(len(tactile_predictions[0]))], [i for i in range(len(tactile_predictions[0]))])\n",
    "plt.show()        \n",
    "mse_loss = torch.nn.MSELoss()\n",
    "# print(\"MAE timestep + 1: \", np.mean(np.asarray([mse_loss(np.asarray(pred.cpu().detach()), np.asarray(gt.cpu().detach()))  for pred, gt in zip(predicted_data_t1, groundtruth_data)])))\n",
    "# print(\"MAE timestep + 5: \", mse_loss(torch.tensor(predicted_data_t5), torch.tensor(groundtruth_data)))\n",
    "# print(\"MAE timestep + 9: \", mse_loss(torch.tensor(predicted_data_t9), torch.tensor(groundtruth_data)))\n",
    "\n",
    "model_path = \"/home/user/Robotics/slip_detection_model/slip_detection_model/manual_data_models/models/simple_model_001/\"\n",
    "# test data\n",
    "index = 0\n",
    "titles = [\"sheerx\", \"sheery\", \"normal\"]\n",
    "for j in range(3):\n",
    "    for i in range(16):\n",
    "        groundtruth_taxle = []\n",
    "        predicted_taxel = []\n",
    "        predicted_taxel_t1 = []\n",
    "        predicted_taxel_t5 = []\n",
    "        predicted_taxel_t9 = []\n",
    "        # good = 140, 145 (lifting up the )\n",
    "        for k in range(len(predicted_data_t1)):#310, 325):#len(predicted_data_t1)):  # add in length of context data\n",
    "            predicted_taxel_t1.append(predicted_data_t1[k][j+i].cpu().detach().numpy())\n",
    "            predicted_taxel_t5.append(predicted_data_t5[k][j+i].cpu().detach().numpy())\n",
    "            predicted_taxel_t9.append(predicted_data_t9[k][j+i].cpu().detach().numpy())\n",
    "            groundtruth_taxle.append(groundtruth_data[k][j+i].cpu().detach().numpy())\n",
    "\n",
    "        index += 1\n",
    "        fig, ax1 = plt.subplots()\n",
    "        ax1.set_xlabel('time step')\n",
    "        ax1.set_ylabel('tactile reading')\n",
    "        ax1.plot(predicted_taxel_t1, alpha=0.5, c=\"b\", label=\"t1\")\n",
    "        ax1.plot(predicted_taxel_t5, alpha=0.5, c=\"k\", label=\"t5\")\n",
    "        ax1.plot(predicted_taxel_t9, alpha=0.5, c=\"g\", label=\"t10\")\n",
    "        ax1.plot(groundtruth_taxle, alpha=0.5, c=\"r\", label=\"gt\")\n",
    "        ax1.tick_params(axis='y')\n",
    "        ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "        ax2.set_ylabel('loss')  # we already handled the x-label with ax1\n",
    "        ax2.plot([i for i in range(len(groundtruth_data))], [mse_loss(predicted_data_t9[i], groundtruth_data[i]) for i in range(len(groundtruth_data))], alpha=0.5)\n",
    "        fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "        fig.subplots_adjust(top=0.90)\n",
    "        ax1.legend(loc=\"upper right\")\n",
    "        plt.title(\"Simple_LSTM tactile \" + str(index))\n",
    "        plt.savefig(model_path + '/' + str(experiment_to_test) + '/sample_test_with_loss_' + str(index) + '.png', dpi=300)\n",
    "        plt.show()\n",
    "\n",
    "        fig, ax1 = plt.subplots()\n",
    "        ax1.set_xlabel('time step')\n",
    "        ax1.set_ylabel('tactile reading')\n",
    "        ax1.plot(predicted_taxel_t1, alpha=0.5, c=\"b\", label=\"t1\")\n",
    "        ax1.plot(groundtruth_taxle, alpha=0.5, c=\"r\", label=\"gt\")\n",
    "        ax1.tick_params(axis='y')\n",
    "        ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "        ax2.set_ylabel('loss')  # we already handled the x-label with ax1\n",
    "        ax2.plot([i for i in range(len(groundtruth_data))], [mse_loss(predicted_data_t9[i], groundtruth_data[i]) for i in range(len(groundtruth_data))], alpha=0.5)\n",
    "        fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "        fig.subplots_adjust(top=0.90)\n",
    "        ax1.legend(loc=\"upper right\")\n",
    "        plt.title(\"Simple_LSTM tactile \" + str(index))\n",
    "        plt.savefig(model_path + '/' + str(experiment_to_test) + '/T0sample_test_with_loss_' + str(index) + '.png', dpi=300)\n",
    "        plt.show()\n",
    "        \n",
    "        fig, ax1 = plt.subplots()\n",
    "        ax1.set_xlabel('time step')\n",
    "        ax1.set_ylabel('tactile reading')\n",
    "        ax1.plot(predicted_taxel_t5, alpha=0.5, c=\"b\", label=\"t5\")\n",
    "        ax1.plot(groundtruth_taxle, alpha=0.5, c=\"r\", label=\"gt\")\n",
    "        ax1.tick_params(axis='y')\n",
    "        ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "        ax2.set_ylabel('loss')  # we already handled the x-label with ax1\n",
    "        ax2.plot([i for i in range(len(groundtruth_data))], [mse_loss(predicted_data_t9[i], groundtruth_data[i]) for i in range(len(groundtruth_data))], alpha=0.5)\n",
    "        fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "        fig.subplots_adjust(top=0.90)\n",
    "        ax1.legend(loc=\"upper right\")\n",
    "        plt.title(\"Simple_LSTM tactile \" + str(index))\n",
    "        plt.savefig(model_path + '/' + str(experiment_to_test) + '/T5sample_test_with_loss_' + str(index) + '.png', dpi=300)\n",
    "        plt.show()\n",
    "            \n",
    "        fig, ax1 = plt.subplots()\n",
    "        ax1.set_xlabel('time step')\n",
    "        ax1.set_ylabel('tactile reading')\n",
    "        ax1.plot(predicted_taxel_t9, alpha=0.5, c=\"b\", label=\"t10\")\n",
    "        ax1.plot(groundtruth_taxle, alpha=0.5, c=\"r\", label=\"gt\")\n",
    "        ax1.tick_params(axis='y')\n",
    "        ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "        ax2.set_ylabel('loss')  # we already handled the x-label with ax1\n",
    "        ax2.plot([i for i in range(len(groundtruth_data))], [mse_loss(predicted_data_t9[i], groundtruth_data[i]) for i in range(len(groundtruth_data))], alpha=0.5)\n",
    "        fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "        fig.subplots_adjust(top=0.90)\n",
    "        ax1.legend(loc=\"upper right\")\n",
    "        plt.title(\"Simple_LSTM tactile \" + str(index))\n",
    "        plt.savefig(model_path + '/' + str(experiment_to_test) + '/T10sample_test_with_loss_' + str(index) + '.png', dpi=300)\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

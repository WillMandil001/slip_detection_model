{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "animal-inflation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import csv\n",
    "import tqdm\n",
    "import click\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from string import digits\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "seed = 42\n",
    "epochs = 1000\n",
    "batch_size = 32\n",
    "learning_rate = 1e-3\n",
    "context_frames = 10\n",
    "sequence_length = 16\n",
    "lookback = sequence_length\n",
    "\n",
    "context_epochs = 20\n",
    "context_batch_size = 1\n",
    "context_learning_rate = 1e-3\n",
    "context_data_length = 20\n",
    "\n",
    "valid_train_split = 0.8  # precentage of train data from total\n",
    "test_train_split = 0.9  # precentage of train data from total\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")#  use gpu if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "distinct-property",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator:\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "        data_map = []\n",
    "        with open(data_dir + 'map.csv', 'r') as f:  # rb\n",
    "            reader = csv.reader(f)\n",
    "            for row in reader:\n",
    "                data_map.append(row)\n",
    "\n",
    "        if len(data_map) <= 1: # empty or only header\n",
    "            print(\"No file map found\")\n",
    "            exit()\n",
    "\n",
    "        self.data_map = data_map\n",
    "\n",
    "    def load_full_data(self):\n",
    "        dataset_train = FullDataSet(self.data_dir, self.data_map, type_=\"train\")\n",
    "        dataset_valid = FullDataSet(self.data_dir, self.data_map, type_=\"valid\")\n",
    "        dataset_test = FullDataSet(self.data_dir, self.data_map, type_=\"test\")\n",
    "        transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "        train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "        valid_loader = torch.utils.data.DataLoader(dataset_valid, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=False)\n",
    "        return train_loader, valid_loader, test_loader\n",
    "\n",
    "\n",
    "class FullDataSet():\n",
    "    def __init__(self, data_dir, data_map, type_=\"train\"):\n",
    "        dataset_full = []\n",
    "        for index, value in enumerate(data_map[1:]):  # ignore header\n",
    "            robot = np.load(data_dir + value[0])\n",
    "            xela1 = np.load(data_dir + value[1])\n",
    "            xela2 = np.load(data_dir + value[2])\n",
    "            for i in range(len(robot)):\n",
    "                dataset_full.append([robot[i].astype(np.float32),\n",
    "                                     xela1[i].astype(np.float32),\n",
    "                                     xela2[i].astype(np.float32),\n",
    "                                     index,\n",
    "                                     i])\n",
    "        if type_ == \"train\":\n",
    "            self.samples = dataset_full[0:int(len(dataset_full)*test_train_split)]\n",
    "        elif type_ == \"valid\":\n",
    "            self.samples = dataset_full[int(len(dataset_full)*(valid_train_split)):int(len(dataset_full)*test_train_split)]\n",
    "        elif type_ == \"test\":\n",
    "            self.samples = dataset_full[int(len(dataset_full)*test_train_split):-1]\n",
    "\n",
    "        data_map = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return(self.samples[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "welsh-swaziland",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FullModel, self).__init__()\n",
    "        self.lstm11 = nn.LSTM(48, 48).to(device)  # tactile\n",
    "        self.fc11   = nn.Linear(48, 24)  # tactile\n",
    "        self.relu11 = nn.ReLU()\n",
    "        self.lstm12 = nn.LSTM(24, 24).to(device)  # tactile\n",
    "        self.fc12   = nn.Linear(24, 12)  # tactile\n",
    "        self.relu12 = nn.ReLU()\n",
    "        self.lstm13 = nn.LSTM(12, 12).to(device)  # tactile\n",
    "        self.fc13   = nn.Linear(12, 6)  # tactile\n",
    "        self.relu13 = nn.ReLU()\n",
    "\n",
    "        self.lstm21 = nn.LSTM(6, 6).to(device)  # pos_vel\n",
    "\n",
    "        self.fc31 = nn.Linear(12, 24)  # tactile + pos_vel\n",
    "        self.relu31 = nn.ReLU()\n",
    "        self.lstm31 = nn.LSTM(24, 24).to(device)  # tactile + pos_vel\n",
    "        self.fc32 = nn.Linear(24, 48)  # tactile + pos_vel\n",
    "        self.relu32 = nn.ReLU()\n",
    "        self.lstm32 = nn.LSTM(48, 48).to(device)  # tactile + pos_vel\n",
    "\n",
    "        self.fc41 = nn.Linear(96, 48)  # tactile + pos_vel + tactile_start\n",
    "        self.relu41 = nn.ReLU()\n",
    "\n",
    "        \n",
    "    def forward(self, tactiles, actions):\n",
    "        state = actions[0]\n",
    "        state.to(device)\n",
    "        batch_size__ = tactiles.shape[1]\n",
    "\n",
    "        hidden11 = (torch.rand(1,batch_size__,48).to(device), torch.rand(1,batch_size__,48).to(device))\n",
    "        hidden12 = (torch.rand(1,batch_size__,24).to(device), torch.rand(1,batch_size__,24).to(device))\n",
    "        hidden13 = (torch.rand(1,batch_size__,12).to(device), torch.rand(1,batch_size__,12).to(device))\n",
    "        hidden21 = (torch.rand(1,batch_size__,6).to(device), torch.rand(1,batch_size__,6).to(device))\n",
    "        hidden31 = (torch.rand(1,batch_size__,24).to(device), torch.rand(1,batch_size__,24).to(device))\n",
    "        hidden32 = (torch.rand(1,batch_size__,48).to(device), torch.rand(1,batch_size__,48).to(device))\n",
    "\n",
    "        outputs = []\n",
    "        for index, (sample_tactile, sample_action) in enumerate(zip(tactiles.squeeze(), actions.squeeze())):\n",
    "            sample_tactile.to(device)\n",
    "            sample_action.to(device)\n",
    "            # 2. Run through lstm:\n",
    "            if index > context_frames-1:\n",
    "                out11, hidden11 = self.lstm11(out43.unsqueeze(0).to(device), hidden11)\n",
    "                out12 = self.fc11(out11.cpu().detach())\n",
    "                out13 = self.relu11(out12)\n",
    "                out14, hidden12 = self.lstm12(out13.to(device), hidden12)\n",
    "                out15 = self.fc12(out13.cpu().detach())\n",
    "                out16 = self.relu12(out15)\n",
    "                out17, hidden13 = self.lstm13(out16.to(device), hidden13)\n",
    "                out18 = self.fc13(out17.cpu().detach())\n",
    "                out19 = self.relu13(out18)\n",
    "\n",
    "                out21, hidden2 = self.lstm21(sample_action.unsqueeze(0), hidden21)\n",
    "                robot_and_tactile = torch.cat((out21.squeeze(), out19.squeeze().to(device)), 1)\n",
    "\n",
    "                out31 = self.fc31(robot_and_tactile.cpu().detach())\n",
    "                out32 = self.relu31(out31.unsqueeze(0))\n",
    "                out33, hidden31 = self.lstm31(out32.to(device), hidden31)\n",
    "                out34 = self.fc32(out33.cpu().detach())\n",
    "                out35 = self.relu32(out34)\n",
    "                out36, hidden32 = self.lstm32(out35.to(device), hidden32)\n",
    "\n",
    "                out41 = torch.cat((out36.squeeze(), out11.squeeze()), 1)\n",
    "                out42 = self.fc41(out41.cpu().detach())\n",
    "                out43 = self.relu41(out42)\n",
    "\n",
    "                outputs.append(out43.squeeze())\n",
    "\n",
    "            else:\n",
    "                out11, hidden11 = self.lstm11(sample_tactile.unsqueeze(0), hidden11)\n",
    "                out12 = self.fc11(out11.cpu().detach())\n",
    "                out13 = self.relu11(out12)\n",
    "                out14, hidden12 = self.lstm12(out13.to(device), hidden12)\n",
    "                out15 = self.fc12(out13.cpu().detach())\n",
    "                out16 = self.relu12(out15)\n",
    "                out17, hidden13 = self.lstm13(out16.to(device), hidden13)\n",
    "                out18 = self.fc13(out17.cpu().detach())\n",
    "                out19 = self.relu13(out18)\n",
    "\n",
    "                out21, hidden2 = self.lstm21(sample_action.unsqueeze(0), hidden21)\n",
    "                robot_and_tactile = torch.cat((out21.squeeze(), out19.squeeze().to(device)), 1)\n",
    "\n",
    "                out31 = self.fc31(robot_and_tactile.cpu().detach())\n",
    "                out32 = self.relu31(out31.unsqueeze(0))\n",
    "                out33, hidden31 = self.lstm31(out32.to(device), hidden31)\n",
    "                out34 = self.fc32(out33.cpu().detach())\n",
    "                out35 = self.relu32(out34)\n",
    "                out36, hidden32 = self.lstm32(out35.to(device), hidden32)\n",
    "\n",
    "                out41 = torch.cat((out36.squeeze(), out11.squeeze()), 1)\n",
    "                out42 = self.fc41(out41.cpu().detach())\n",
    "                out43 = self.relu41(out42)\n",
    "\n",
    "        return torch.stack(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "solved-treasurer",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "        self.train_full_loader, self.valid_full_loader, self.test_full_loader = BG.load_full_data()\n",
    "        self.full_model = FullModel()\n",
    "        self.criterion = nn.L1Loss()\n",
    "        self.optimizer = optim.Adam(self.full_model.parameters(), lr=learning_rate)\n",
    "\n",
    "    def train_full_model(self):\n",
    "        plot_training_loss = []\n",
    "        plot_validation_loss = []\n",
    "        previous_val_mean_loss = 1.0\n",
    "        early_stop_clock = 0\n",
    "        progress_bar = tqdm.tqdm(range(0, epochs), total=(epochs*len(self.train_full_loader)))\n",
    "        mean_test = 0\n",
    "        for epoch in progress_bar:\n",
    "            loss = 0\n",
    "            losses = 0.0\n",
    "            for index, batch_features in enumerate(self.train_full_loader):\n",
    "                action = batch_features[0].permute(1,0,2).to(device)\n",
    "                tactile = batch_features[1].permute(1,0,2).to(device)\n",
    "\n",
    "                tactile_predictions = self.full_model.forward(tactiles=tactile, actions=action) # Step 3. Run our forward pass.\n",
    "                self.optimizer.zero_grad()\n",
    "                loss = self.criterion(tactile_predictions.to(device), tactile[context_frames:])\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                losses += loss.item()\n",
    "                if index:\n",
    "                    mean = losses / index\n",
    "                else:\n",
    "                    mean = 0\n",
    "                progress_bar.set_description(\"epoch: {}, \".format(epoch) + \"loss: {:.4f}, \".format(float(loss.item())) + \"mean loss: {:.4f}, \".format(mean))\n",
    "                progress_bar.update()\n",
    "            plot_training_loss.append(mean)\n",
    "\n",
    "            val_losses = 0.0\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for index__, batch_features in enumerate(self.valid_full_loader):\n",
    "                    action = batch_features[0].permute(1,0,2).to(device)\n",
    "                    tactile = batch_features[1].permute(1,0,2).to(device)\n",
    "\n",
    "                    tactile_predictions = self.full_model.forward(tactiles=tactile, actions=action)  # Step 3. Run our forward pass.\n",
    "                    self.optimizer.zero_grad()\n",
    "                    val_loss = self.criterion(tactile_predictions.to(device), tactile[context_frames:])\n",
    "                    val_losses += val_loss.item()\n",
    "\n",
    "            print(\"Validation mean loss: {:.4f}, \".format(val_losses / index__))\n",
    "            plot_validation_loss.append(val_losses / index__)\n",
    "            if previous_val_mean_loss < val_losses / index__:\n",
    "                early_stop_clock +=1\n",
    "                previous_val_mean_loss = val_losses / index__ \n",
    "                if early_stop_clock == 6:\n",
    "                    print(\"Early stopping\")\n",
    "                    break\n",
    "            else:\n",
    "                early_stop_clock = 0\n",
    "                previous_val_mean_loss = val_losses / index__ \n",
    "        plt.plot(plot_training_loss, c=\"r\", label=\"train loss MAE\")\n",
    "        plt.plot(plot_validation_loss, c='b', label=\"val loss MAE\")\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-survival",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 0.1372, mean loss: 0.1810, :   0%|          | 2845/2842000 [02:28<878:02:22,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.1454, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 2, loss: 0.1077, mean loss: 0.1451, :   0%|          | 5688/2842000 [05:00<606:23:01,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.1212, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 3, loss: 0.1103, mean loss: 0.1504, :   0%|          | 8532/2842000 [07:25<614:01:41,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.1187, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 4, loss: 0.1072, mean loss: 0.1484, :   0%|          | 11374/2842000 [09:55<898:03:04,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.1172, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 5, loss: 0.1149, mean loss: 0.1487, :   1%|          | 14217/2842000 [12:20<531:56:47,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.1163, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 6, loss: 0.1066, mean loss: 0.1361, :   1%|          | 17059/2842000 [14:26<751:12:40,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.1155, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 7, loss: 0.1101, mean loss: 0.1423, :   1%|          | 19900/2842000 [16:30<770:14:52,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.1145, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 8, loss: 0.1144, mean loss: 0.1343, :   1%|          | 22743/2842000 [18:32<544:54:28,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.1149, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 9, loss: 0.1045, mean loss: 0.1306, :   1%|          | 25585/2842000 [20:36<754:47:11,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.1140, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 10, loss: 0.1146, mean loss: 0.1473, :   1%|          | 28426/2842000 [23:00<872:25:26,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.1139, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 11, loss: 0.1060, mean loss: 0.1330, :   1%|          | 31270/2842000 [25:18<642:18:19,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.1139, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 12, loss: 0.1039, mean loss: 0.1400, :   1%|          | 34110/2842000 [27:41<862:46:59,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.1147, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 13, loss: 0.1039, mean loss: 0.1345, :   1%|▏         | 36954/2842000 [29:53<597:20:38,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.1133, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 14, loss: 0.1070, mean loss: 0.1365, :   1%|▏         | 39795/2842000 [32:03<600:16:57,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.1120, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 15, loss: 0.1055, mean loss: 0.1342, :   2%|▏         | 42637/2842000 [34:13<825:10:48,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.1113, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 16, loss: 0.1095, mean loss: 0.1440, :   2%|▏         | 45478/2842000 [36:27<1030:52:26,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean loss: 0.1116, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 16, loss: 0.1077, mean loss: 0.1047, :   2%|▏         | 47125/2842000 [37:48<33:22:26, 23.26it/s]  "
     ]
    }
   ],
   "source": [
    "data_dir = '/home/user/Robotics/Data_sets/slip_detection/manual_slip_detection/'\n",
    "BG = BatchGenerator(data_dir)\n",
    "print(\"done\")\n",
    "\n",
    "MT = ModelTrainer(data_dir)\n",
    "MT.train_full_model()\n",
    "print(\"finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-chuck",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
